\documentclass[12pt]{article}

\usepackage{ishn}

\makeindex[intoc]

\begin{document}

\hypersetup{pageanchor=false}
\begin{titlepage}
	\begin{center}
		\vspace*{1em}
		\Huge
		\textbf{II Applied Probability}

		\vspace{1em}
		\large
		Ishan Nath, Lent 2023

		\vspace{1.5em}

		\Large

		Based on Lectures by Dr. Sourav Sarkar

		\vspace{1em}

		\large
		\today
	\end{center}
	
\end{titlepage}
\hypersetup{pageanchor=true}

\tableofcontents

\newpage

\section{Continuous-time Markov Chains}
\label{sec:continuous_time_markov_chains}

A sequence of random variables is called a \emph{stochastic process}\index{stochastic process}. The process $X = (X_n)_{n \in \mathbb{N}}$ is called a \emph{discrete-time Markov chain}\index{discrete-time Markov chain} with state space $I$ if for all $x_0, x_1, \ldots, x_n \in I$,
\[
\mathbb{P}(X_n = x_n \mid X_{n-1} = x_{n-1}, \ldots, X_1 = x_1, X_0 = x_0) = \mathbb{P}(X_n = x_n \mid X_{n-1} = x_{n-1})
.\]
It is \emph{time-homogeneous}\index{time-homogeneous} if
\[
\mathbb{P}(X_{n+1} = y \mid X_n = x)
\]
is independent of $n$. If it is time-homogeneous, we can write $P = (P_{x,y})_{x, y \in I}$ for the \emph{transition matrix}\index{transition matrix}, where
\[
P_{x,y} = \mathbb{P}(X_{1} = y \mid X_0 = x) = \mathbb{P}(X_{n+1} = y \mid X_0 = x)
.\]
The data associated to every time-homogeneous Markov chain is the transition matrix $P$ and the initial distribution $\mu$, where $\mathbb{P}(X_0 = x_0) = \mu(x_0)$ for all $x_0 \in I$.

From now on, we let $I$ denote a countable state space, and $(\Omega, \mathcal{F}, \mathbb{P})$ denote the probability space on which all relevant random variables are defined.

\begin{definition}
	$X = (X(t) \mid t \geq 0)$ is a (right-continuous) \emph{continuous time random process}\index{continuous time random process} with values in $I$ if
	\begin{enumerate}[(a)]
		\item For all $t \geq 0$, $X(t)$ (or $X_t$) is a random variable such that $X(t) : \Omega \to I$.
		\item For all $w \in \Omega$, $t \mapsto X_t(\omega)$ is right-continuous.
	\end{enumerate}
\end{definition}

In our case, since $I$ is countable, this means for all $w \in \Omega$, and for all $t \geq 0$, there exists $\eps > 0$ (dependent of $w$ and $t$) such that $X_t(w) = X_{s}(w)$, for all $s \in [t, t+\eps]$.

\begin{proposition}
	A right-continuous random process is determined by its finite dimensional distribution
	\[
	\mathbb{P}(X_{t_0} = i_0, X_{t_i} = i_1, \ldots, X_{t_n} = i_n)
	.\]
\end{proposition}

For every $w \in \Omega$, the path $t \mapsto X_t(\omega)$ of a right-continuous process is always constant for a while. There are three possibilities for its behaviour:
\begin{enumerate}[(i)]
	\item The path may make infinitely many jumps, but only finitely many in any interval $[0, t]$.
	\item The path makes finitely many jumps and gets absorbed in some state.
	\item The path makes infinitely many jumps in a finite time interval. After the explosion time, the process starts up again.
\end{enumerate}

We denote $J_0 = 0, J_1, J_2, \ldots$ as the \emph{jump times}\index{jump times}, and $S_1, S_2, \ldots$ the \emph{holding times}\index{holding times}. We can define $J_{i}$ as $J_0 = 0$, and
\[
	J_{n+1} = \inf\{t \geq J_n \mid X_{t} \neq X_{J_n}\}
.\]
Then we define
\[
S_n =
\begin{cases}
	J_n - J_{n-1} & J_n \neq \infty, \\
	\infty & \text{otherwise}.
\end{cases}
\]
By right-continuity, $S_n > 0$ for all $n$. If $J_{n+1} = \infty$ for some $n$, then we define $X_{\infty} = X_{J_n}$ as the final value. Otherwise it is not defined.

The \emph{explosion time}\index{explosion time} $S$ is defined by
\[
S = \sup_{n}J_n = \sum_{n = 1}^{\infty}S_n
.\]

We are not going to consider what happens to a chain after explosion. Instead, we will set $X_t = \infty$ for all $t > S$.

\begin{definition}
	A right-continuous, continuous time random process $X = (X_t)_{t \geq 0}$ has the \emph{Markov property}\index{Markov property} and is called a \emph{continuous time Markov chain}\index{continuous time Markov chain} if for all $i_1, \ldots, i_n \in I$ and $0 < t_1 < \cdots < t_n$,
	\[
	\mathbb{P}(X_{t_n} = i_n \mid X_{t_{n-1}} = i_{n-1}, \ldots, X_{t_1} = i_1) = \mathbb{P}(X_{t_n} = i_n \mid X_{t_{n-1}} = i_{n-1})
	.\]
\end{definition}

For all $k > 0$, $X_n = X(k_n)$ defines a discrete Markov chain.

\begin{definition}
	We define the \emph{jump chain}\index{jump chain} of $(X_t)_{t \geq 0}$ by setting $Y_n = X_{J_n}$ for all $n$.
\end{definition}

\begin{definition}
	The transition probabilities are defined as
	\[
	P_{ij}(s,t) = \mathbb{P}(X_t = j \mid X_s = i)
	.\]
	The continuous times Markov chain is called \emph{time-homogeneous}\index{time-homogeneous} if the transition probabilities depend only on $t - s$, or $P_{ij}(s,t) = P_{ij}(0,t-s)$.
\end{definition}

As in the discrete time case, a (time-homogeneous) Markov chain is characterised by its initial distribution $\lambda$, and its family of transition matrices
\[
	(P(t))_{t \geq 0} = (P_{ij}(t))_{\substack{i,j\\t \geq 0}}
.\]
These form a semigroup (a group without inverses).

It is easy to see that:
\begin{itemize}
	\item $P(0)$ is the identity.
	\item $P(t)$ is a stochastic matrix for all $t$.
	\item $P(t+s) = P(t)P(s)$ for all $s, t$ (Chapman-Kolmogorov equation).\index{Chapman-Kolmogorov equation}
\end{itemize}
To prove this, note
\begin{align*}
	P_{xz}(t+s) &= \mathbb{P}(X_{t+s} = z \mid X_0 = x) \\
		    &= \sum_{y \in I} \mathbb{P}(X_{t+s} = z \mid X_0 = x, X_t = y) \mathbb{P}(X_t = y \mid X_0 = x) \\
		    &= \sum_{y \in I} \mathbb{P}(X_{t+s} = z \mid X_t = y) \mathbb{P}(X_t = y \mid X_0 = x) \\
		    &= \sum_{y \in I} \mathbb{P}(X_s = z \mid X_0 = y) \mathbb{P}(X_t = y \mid X_0 = x) \\
		    &= \sum_{y \in I}P_{yz}(s) P_{xy}(t) = P_x(t) P_z(s).
\end{align*}

\subsection{Holding Times}
\label{sub:holding_times}

Let $X$ be a (right-cont. cont. time time-homogeneous) Markov chain on a countable state-space $I$, and suppose it starts from $x \in I$. Then how long does it stay in the state $x$?

We call $S_x$ the \emph{holding time}\index{holding time} at state $x$. Since $X$ is right continuous, $S_x > 0$. Let $s, t \geq 0$. Then,
\begin{align*}
	\mathbb{P}(S_x > t + s \mid S_x > s) &= \mathbb{P}(X_u = x \, \forall u \in [0, t+s] \mid X_u = x \, \forall u \in [0,s]) \\
					     &= \mathbb{P}(X_u = x \, \forall u \in [s, t+s] \mid X_u = x \, \forall u \in [0, s]) \\
					     &= \mathbb{P}(X_u = x \, \forall u \in [s, t+s] \mid X_s = x) \\
					     &= \mathbb{P}(X_u = x \, \forall u \in [0, t] \mid X_0 = x) = \mathbb{P}(S_x > t).
\end{align*}

Thus $S_x$ has the \emph{memoryless property}\index{memoryless property}. The same holds for the holding time at any state.

By the next theorem, we will get that $S_x$ has the exponential distribution, say with parameter $q_{x}$.

\begin{theorem}[Memoryless Property]
	Let $S$ be a positive random variable. Then $S$ has the \emph{memoryless property}, i.e. $\mathbb{P}(S > t+s \mid S > s) = \mathbb{P}(S > t)$ for all $s, t \geq 0$ if and only if $S$ has the exponential distribution.
\end{theorem}

Recall that $X \sim \Exp(\lambda)$ if $\mathbb{P}(X > x) = e^{-\lambda x}$, and $X \geq 0$.

\begin{proofbox}
	We show a memoryless random variable is exponential. Set $F(t) = \mathbb{P}(S > t)$. Then $F(s + t) = F(s)F(t)$ for all $s, t \geq 0$. Since $S$ is a positive random variable, there exists $n \in \mathbb{N}$ large enough such that
	\[
	F(1/n) = \mathbb{P}(S > 1/n) > 0
	.\]
	Then, we get $F(1) = F(1/n + 1/n + \cdots + 1/n) = (F(1/n))^{n} > 0$. So we can set $F(1) = e^{-\lambda}$, for some $\lambda \geq 0$.

	For $k \in \mathbb{N}$, we get $F(k) = F(1 + \cdots + 1) = (F(1))^{k} = e^{-\lambda k}$. Then, for all rationals, we get
	\[
		F(p/q) = (F(1/q))^{p} = [(F(1/q))^{q}]^{p/q} = [F(1/q + \cdots + 1/q)]^{p/q} = e^{-\lambda p/q}
	.\]
	For any $t \geq 0$, and for any $r, s \in \mathbb{Q}$ such that $r \leq t \leq s$, since $F$ is decreasing,
	\[
	e^{-\lambda s} = F(s) \leq F(t) \leq F(r) = e^{-\lambda r}
	.\]
	Letting $r, s \to t$, we get $F(t) = e^{-\lambda t}$.
\end{proofbox}

\newpage

\section{Poisson Process}

We are now going to look at the simplest (and most important) example of a continuous time Markov chain, the \emph{Poisson Process}\index{Poisson process}.

Suppose $S_1, S_2, \ldots$ are iid random variables, with $S_1 \sim \Exp(\lambda)$. Define the jump times to be $J_0 = 0$, $J_1 = S_1$, and in general, $J_n = S_1 + \cdots + S_n$, for all $n$.

We set $X_t = i$ if $J_i \leq t < J_{i+1}$, for all $i = 0, 1, 2, \ldots$. Here, $I= \{0, 1, 2, \ldots\}$, and note the Poisson process is right-continuous and increasing.

Then $X$ is called a Poisson process of parameter/intensity $\lambda$, which we denote $PP(\lambda)$. We sometimes refer to the jump times $(J_i)$ as the \emph{points}\index{points} of the Poisson process. Then $X_t$ counts the number of points in $[0, t]$.

\begin{theorem}[Markov Property]\index{Markov property}
	Let $(X_t)_{t \geq 0}$ be $PP(\lambda)$. Then for all $s \geq 0$, the process $(X_{s+t}-X_s)_{t \geq 0}$ is also $PP(\lambda)$, and is independent of $(X_{\gamma})_{0 \leq \gamma \leq s}$.
\end{theorem}

\begin{proofbox}
	Set $Y_t = X_{t+s} - X_s$ for all $t \geq 0$, and let $i = \{0, 1, 2, \ldots\}$. We condition on $\{X_s = i\}$. Then the jump times for the process $Y$ are $J_{i+1}-s, J_{i+2}-s, \ldots$, and the holding times are
	\[
	T_1 = J_{i+1} - s = S_{i+1} - (s - J_i)
	,\]
	and $T_2 = S_{i+2}, T_3 = S_{i+3}$, and so on. Here $J$ and $S$ are the jump times and holding times for $X$. Since
	\begin{align*}
		\{X_{s} = i\} &= \{J_i \leq s\} \cap \{s < J_{i+1}\} \\
			      &= \{J_i \leq s\} \cap \{S_{i+1} > s - J_i\},
	\end{align*}
	conditional on $\{X_s = i\}$, by the memoryless property of the exponential distribution, we can see that $T_1 \sim \Exp(\lambda)$. Moreover, the times $T_j$ for $j \geq 2$ are independent of $S_k$ for $k \leq i+1$, and hence independent of $(X_{\gamma})_{\gamma \leq s}$, and they have iid $\Exp(\lambda)$ distribution.

	Thus $(X_{s+t}-X_s)_{t\geq 0} \sim PP(\lambda) \perp (X_{\gamma})_{0 \leq \gamma \leq s}$.
\end{proofbox}

Similarly, we can show the \emph{Strong Markov property} for $PP(\lambda)$. Recall that a random variable $T \in [0, \infty]$ is called a \emph{stopping time}\index{stopping time} if for all $t$, the event $\{T \leq t\}$ depends only on $(X_s)_{s \leq t}$.

\begin{theorem}[Strong Markov Property]\index{strong Markov property}
	Let $(X_t)_{t \geq 0}$ be $PP(\lambda)$, and $T$ a stopping time. Then conditional on $T < \infty$, the process $(X_{T+t} - X_T)_{t \geq 0}$ is $PP(\lambda)$ and independent of $(X_s)_{s \leq T}$.
\end{theorem}

\begin{theorem}
	Let $(X_t)_{t \geq 0}$ be an increasing right continuous process taking values in $\{0, 1, 2, \ldots\}$ with $X_0 = 0$. Let $\lambda > 0$. Then the following are equivalent:
	\begin{enumerate}[\normalfont(a)]
		\item The holding times $S_1, S_2, \ldots$ are iid $\Exp(\lambda)$, and the jump chain is given by $Y_n = n$.
		\item (Infinitesimal definition) $X$ has independent increments, and as $h \downarrow 0$ uniformly in $t$, we have
			\begin{align*}
				\mathbb{P}(X_{t+h} - X_t = 1) &= \lambda h + o(h), \\
				\mathbb{P}(X_{t+h} - X_t = 0) &= 1 - \lambda h + o(h).
			\end{align*}
			This means that $\mathbb{P}(X_{t+h} - X_t \geq 2) = o(h)$.
		\item $X$ has independent and stationary increments and for all $t \geq 0$, $X_t \sim \Poisson(\lambda t)$.
	\end{enumerate}
\end{theorem}

\begin{proofbox}
	We show (a) implies (b). If (a) holds, then the increments are independent and stationary. Using the fact it is stationary, we have uniformly in $t$ as $h \to 0$,
	\[
	\mathbb{P}(X_{t+h}-X_t = 0) = \mathbb{P}(X_h = 0) = \mathbb{P}(S_1 > h) = e^{-\lambda h} = 1 - \lambda h + o(h),
	\]
	\[
	\mathbb{P}(X_{t+h} - X_t \geq 1) = \mathbb{P}(X_h \geq 1) = \mathbb{P}(S_1 \leq h) = 1 - e^{-\lambda h} = \lambda h + o(h)
	,\]
	\begin{align*}
		\mathbb{P}(X_{t+h}-X_t \geq 2) &= \mathbb{P}(X_h \geq 2) = \mathbb{P}(S_1 + S_2 \leq h) \leq \mathbb{P}(S_1 \leq h)^2 \\
					       &= (\lambda h + o(h))^2 = o(h).
	\end{align*}
	Now we show (b) implies (c). If $X$ satisfies (b), then $(X_{t+s}-X_s)_{t \geq 0}$ also satisfies (b), so $X$ has independent and stationary increments. Set $p_j = \mathbb{P}(X_t = j)$. Then since the increments are independent and $X$ is increasing, for $j \geq 1$,
	\begin{align*}
		p_j(t+h) &= \mathbb{P}(X_{t+h} = j) = \sum_{i = 0}^{j} \mathbb{P}(X_t = j-1) \mathbb{P}(X_{t+h} - X_t = i) \\
			 &= p_j(t)(1 - \lambda h + o(h)) + p_{j-1}(t)(\lambda h + o(h)) + o(h).
	\end{align*}
	Rearranging this, we get
	\[
	\frac{p_j(t+h) - p_j(t)}{h} = - \lambda p_j(t) + \lambda p_{j-1}(t) + o(1)
	.\]
	Setting $s = t+h$, we get
	\[
	\frac{p_j(s+h) - p_j(s)}{h} = - \lambda p_j(s-h) + \lambda p_{j-1}(s-h) + o(1)
	.\] 
	These equations imply $p_j(t)$ is a continuous function of $t$, and as $h \to 0$,
	\[
	p_j'(t) = - \lambda p_j(t) + \lambda p_{j-1}(t)
	.\]
	Differentiating $e^{\lambda t}p_j(t)$ with respect to $t$, we get that
	\[
		\bigl(e^{\lambda t}p_j(t)\bigr)' = \lambda e^{\lambda t}p_j(t) + e^{\lambda t}p_j'(t) = \lambda e^{\lambda t}p_{j-1}(t)
	.\]
	For $j = 0$, we similarly get $p_0(t+h) = p_0(t)(1 - \lambda h) + o(h)$. So $p_0'(t) = - \lambda p_0(t)$, implying $p_0(t) = e^{-\lambda t}$.

	Since $p_1'(t) = - \lambda p_1(t) + \lambda e^{-\lambda t}$, we get $p_1(t) = \lambda t e^{-\lambda t}$, and by induction,
	\[
	p_k(t) = e^{-\lambda t} \frac{(\lambda t)^{k}}{k!}
	.\]
	So $X_t \sim \Poisson(\lambda t)$.

	Finally we show (c) implies (a). Since $X$ has independent stationary, we can write
	\begin{align*}
		\mathbb{P}(X_{t_1} &= n_1, X_{t_2} = n_2, \ldots, X_{t_k} = n_k) \\
				   &\mathbb{P}(X_{t_1} = n_1) \mathbb{P}(X_{t_2} - X_{t_1} = n_2 - n1) \cdots \mathbb{P}(X_{t_k} - X_{t_{k-1}} = n_k - n_{k-1}) \\
				   &= \mathbb{P}(X_{t_1} = n_1) \mathbb{P}(X_{t_2 - t_1} = n_2 - n_1) \cdots \mathbb{P}(X_{t_k} - X_{t_{k-1}} = n_k - n_{k-1}).
	\end{align*}
	But these probabilities are known; they are Poisson. So (c) determines the finite dimensional distribution of a right-continuous process $X$, hence it determines $X$. As we know the Poisson process produces (c), we get (c) implies (a).
\end{proofbox}

We went through this process to obtain the Poisson distribution for each $X_t$. Let's see if we can do this directly. Note
\begin{align*}
	\mathbb{P}(X_t = n) &= \mathbb{P}(S_1 + \cdots + S_n \leq t < S_1 + \cdots + S_{n+1}) \\
			    &= \mathbb{P}(S_1 + \cdots + S_n \leq t) - \mathbb{P}(S_1 + \cdots + S_{n+1} \leq t) \\
			    &= \int_{0}^{t} \lambda e^{-\lambda x} \frac{(\lambda x)^{n-1}}{(n-1)!} \diff x - \int_{0}^{t} \lambda e^{-\lambda x} \frac{(\lambda x)^{n}}{n!} \diff x \\
			    &= e^{-\lambda t} \frac{(\lambda t)^{n}}{n!},
\end{align*}
from integration by parts, and the fact the sums $S_1 + \cdots + S_n \sim \Gamma(n, \lambda)$.

\begin{theorem}[Superposition]\index{superposition}
	Let $X$ and $Y$ be two independent Poisson processes with parameters $\lambda$ and $\mu$ respectively. Then,
	\[
	Z_t = X_t + Y_t \sim PP(\lambda + \mu)
	.\]
\end{theorem}

\begin{proofbox}
	To prove this, we use (c). $Z$ has stationary with independent processes, and $Z_t \sim \Poisson(\lambda t + \mu_t)$, as it is a sum of independent Poisson distributions.
\end{proofbox}

\begin{theorem}[Thinning]\index{thinning}
	Let $X$ be $PP(\lambda)$, and let $(Z_i)_{i \geq 0}$ be iid $\Ber(p)$. Let $Y$ be a process with values in $\{0, 1, 2, \ldots\}$ which jumps at time $t$ if and only if
	\begin{itemize}
		\item $X$ jumps at time $t$, and
		\item $Z_{X_t} = 1$.
	\end{itemize}
	In other words, we keep every point of $X$ with probability $p$ independently over all points. Then $Y \sim PP(\lambda p)$ and $X - Y$ is an independent Poisson process with parameter $\lambda(1 - p)$.
\end{theorem}

\begin{proofbox}
	We will use the infinitesimal definition. The independence of increments for $Y$ is clear. Since $\mathbb{P}(X_{t+h} - X_t \geq 2) = o(h)$, we have
	\[
	\mathbb{P}(Y_{t+h} - Y_t = 1) = p \cdot\mathbb{P}(X_{t+h} - X_t = 1) + o(h) = \lambda p h + o(h)
	.\]
	We also get
	\begin{align*}
		\mathbb{P}(Y_{t+h} - Y_t = 0) &= \mathbb{P}(X_{t+h} - X_t = 0) + (1-p)\mathbb{P}(X_{t+h}-X_t = 1) + o(h) \\
					      &= 1 - \lambda h + (1-p)(\lambda h + o(h)) + o(h) = 1 - \lambda p h + o(h).
	\end{align*}
	This proves $Y \sim PP(\lambda p)$. Since $X - Y$ is also a thinning of $X$ with probability $1 - p$, $X - Y \sim PP(\lambda(1-p))$.

	Now we prove that $X$ and $X - Y$ are independent. It is enough to show that the finite dimensional distributions of $Y$ and $X-Y$ are independent, so
	\begin{align*}
		\mathbb{P}(Y_{t_1} &= n_1, \ldots, Y_{t_k} = n_k, X_{t_1} - Y_{t_1} = m_1, \ldots, X_{t_k} - Y_{t_k} = m_k) \\
				   &= \mathbb{P}(Y_{t_1} = n_1, \ldots, Y_{t_k} = n_k) \mathbb{P}(X_{t_1} - Y_{t_1} = m_1, \ldots, X_{t_k} - Y_{t_k} = m_k).
	\end{align*}
	We will show this for a fixed $t$. The general case follows from independence of increments. Indeed,
	\begin{align*}
		\mathbb{P}(Y_t &= n, X_t - Y_t = m) = \mathbb{P}(X_t = m+n, Y_t = n) \\
			       &= \mathbb{P}(X_t = m+n) \mathbb{P}(Y_t = n \mid X_t = m + n) \\
			       &= e^{-\lambda t} \frac{(\lambda t)^{m+n}}{(m+n)!} \mathbb{P}(\Bin(m+n,p) = n) \\
			       &= e^{-\lambda t} \frac{(\lambda t)^{m+n}}{(m+n)!} \binom{m+n}{n} p^{n}(1-p)^{n} \\
			       &= e^{-\lambda t p}\frac{(\lambda tp)^{n}}{n!} e^{-\lambda t(1-p)} \frac{(\lambda t(1-p))^{m}}{m!} \\
			       &= \mathbb{P}(Y_t = n) \mathbb{P}(X_t - Y_t = m).
	\end{align*}
\end{proofbox}

\begin{theorem}
	Let $X$ be a Poisson process. Then conditional on the event $\{X_t = n\}$, the jump times $J_1, \ldots, J_n$ are distributed as the order-statistics of $n$ iid $U[0,t]$ random variables, i.e. their joint density is
	\[
		f(t_1, \ldots, t_n) = \frac{n!}{t^{n}} \mathbbm{1} (0 \leq t_1 \leq t_2 \leq \cdots \leq t_n \leq t)
	.\]
\end{theorem}

\begin{proofbox}
	Since $S_1, S_2, \ldots$ are iid $\Exp(\lambda)$, the joint density of $(S_1, \ldots, S_{n+1})$ is
	\[
		\lambda^{n+1}e^{-\lambda(S_1 + \cdots + S_{n+1})} \mathbbm{1} (S_1, \ldots, S_{n+1} \geq 0)
	.\]
	Then the jump times $J_1 = S_1, J_2 = S_1 + S_2, \ldots$ have joint density
	\begin{align*}
		g(t_1,\ldots,t_{n+1})&= \lambda^{n+1}e^{-\lambda t_{n+1}}\mathbbm{1}(0 \leq t_1 \leq \cdots \leq t_{n+1}).
	\end{align*}
	Now taking $A \subset \mathbb{R}^{n}$,
	\begin{align*}
		\mathbb{P}((J_1, \ldots, J_n) \in A \mid X_t = n) &= \frac{\mathbb{P}((J_1, \ldots, J_n) \in A, X_t = n)}{\mathbb{P}(X_t = n)}.
	\end{align*}
	We can calculate
	\begin{align*}
		\mathbb{P}((J_1, \ldots, &J_n) \in A, X_t = n) = \mathbb{P}((J_1, \ldots, J_n) \in A, J_n \leq t < J_{n+1}) \\
							      &= \int_{A, t_{n+1}}g(t_1, \ldots, t_{n+1}) \mathbbm{1}(t_{n+1} > t \geq t_n) \diff \mathbf{t} \diff t_{n+1} \\
							      &= \int_{A} \int_{t_{n+1} = t}^{\infty} \lambda^{n+1} e^{-\lambda t_{n+1}} \mathbbm{1}(0 \leq t_1 \leq \cdots \leq t_n \leq t) \diff \mathbf{t} \diff t_{n+1} \\
							      &= \int_{A} \lambda^{n} e^{-\lambda t} \mathbbm{1} (0 \leq t_1 \leq \cdots \leq t_n \leq t) \diff \mathbf{t}.
	\end{align*}
	We also know that
	\[
	\mathbb{P}(X_t = n) = \frac{e^{-\lambda t} (\lambda t)^{n}}{n!}
	,\]
	so dividing we get
	\begin{align*}
		\mathbb{P}((J_1, \ldots, J_n) \in A \mid X_t = n) &= \int_{A} \frac{n!}{t^{n}} \mathbbm{1} (0 \leq t_1 \leq \cdots \leq t_n \leq t) \diff \mathbf{t} \\
								  &= \int_{A} f(t_1, \ldots, t_n) \diff \mathbf{t},
	\end{align*}
	proving the joint distribution is as desired.
\end{proofbox}

\newpage

\section{Birth Process}
\label{sec:birth_process}

A \emph{birth process}\index{birth process} is a generalization of a Poisson process. For a Poisson process, the rate of going from $i$ to $i + 1$ is $\lambda$, uniform for all $i$. For a birth process, this is $q_i$.

For each $i$, let $S_i$ be $\Exp(q_i)$, such that $S_1, S_2, \ldots$ are independent. Then set $T_i = S_1 + S_2 + \cdots + S_i$, and $X_t = i$ if $J_i \leq t < j_{i+1}$. Then $X$ is called a birth process.

\begin{itemize}
	\item A \emph{simple birth process}\index{simple birth process} is when $q_i = \lambda i$ for all $i$.
	\item A Poisson process is a birth process with $q_i = \lambda$ for all $i$.
\end{itemize}

\subsection{Motivation for Simple Birth Processes}
\label{sub:motivation_for_simple_birth_processes}

At time 0, there is only one individual, so $X_0 = 1$. Each individual has en exponential clock of parameter $\lambda$ independently.

Then, if there are $i$ individuals, then the first clock rings after $\Exp(\lambda i)$ time, and we move from $i$ to $i+1$ individuals. By the memoryless property, the process begins again.

\begin{proposition}
	Let $(T_k)_{k \geq 1}$ be a sequence of independent random variables with $T_k \sim \Exp(q_k)$, and $0 < \sum q_k < \infty$. Let $T = \inf_{k} T_k$. Then,
	\begin{enumerate}[\normalfont(a)]
		\item $T \sim \Exp(\sum q_k)$,
		\item The infimum is attained at a unique point $K$ almost surely, and
			\[
			\mathbb{P}(K = k) = \frac{q_k}{\sum q_k}
			,\]
		\item $T$ and $K$ are independent.
	\end{enumerate}
\end{proposition}

The proof is found on the example sheet.

The main difference between a Poisson process and a birth process is the possibility of explosion in a birth process. Recall that explosion occurs when $\sum S_n < \infty$.

\begin{proposition}
	Let $X$ be a birth process with rates $q_i$ and $X_0 = 1$.
	\begin{enumerate}[\normalfont1.]
		\item If $\sum \frac{1}{q_i} < \infty$, then $\mathbb{P}(\zeta<\infty) = 1$, i.e. the birth process is explosive.
		\item If $\sum \frac{1}{q_i} = \infty$, then $\mathbb{P}(\zeta = \infty) = 1$, i.e. the birth process is non-explosive.
	\end{enumerate}
\end{proposition}

Note that both the Poisson process and simple birth process are part of case 2, hence both are non-explosive.

\begin{proofbox}
	\begin{enumerate}[1.]
		\item If $\sum \frac{1}{q_n} < \infty$, then
			\[
			\mathbb{E}\biggl[ \sum_{n = 1}^{\infty} S_n \biggr] = \sum_{n = 1}^{\infty} \mathbb{E}[S_n] = \sum_{n = 1}^{\infty} \frac{1}{q_n} < \infty
			.\]
			Thus $\zeta = \sum_n S_n < \infty$ almost surely.
		\item If $\sum \frac{1}{q_n} = \infty$, then 
			\[
			\prod_{n = 1}^{\infty} \biggl( 1 + \frac{1}{q_n} \biggr) \geq 1 + \sum_{n = 1}^{\infty} \frac{1}{q_n} = \infty
			.\]
			Then,
			\begin{align*}
				\mathbb{E}[e^{-\zeta}] &= \mathbb{E}\biggl[ \exp \biggl( - \sum_{n = 1}^{\infty} S_n \biggr) \biggr] \\
						       &= \lim_{n \to \infty} \mathbb{E}\biggl[ \exp \biggl( -\sum_{i = 1}^{n} S_i \biggr) \biggr] \\
						       &= \lim_{n \to \infty} \prod_{i = 1}^{n} \mathbb{E}[e^{-S_i}] \\
						       &= \lim_{n \to \infty} \prod_{i = 1}^{n} \frac{1}{1 + 1/q_i} = \prod_{i = 1}^{n} \frac{1}{1 + 1/q_i} = 0.
			\end{align*}
			As $e^{-\zeta} \geq 0$ with $\mathbb{E}[e^{-\zeta}] = 0$, we must have $e^{-\zeta} = 0$ almost surely, so $\mathbb{P}(\zeta = \infty) = 1$.
	\end{enumerate}
\end{proofbox}

\begin{theorem}[Markov Property]\index{Markov property}
	Let $X$ be a birth process with rates $q_i$. Then conditional on $X_s = i$, the process $(X_{s+t})_{t \geq 0}$ is a birth process with rates $q_j$ for $j > i$, starting from $i$ and independent of $(X_\gamma)_{\gamma \leq s}$.
\end{theorem}

This proof is the same for Poisson processes. Moreover, we also have the following similarities to Poisson processes:

\begin{theorem}
	Let $X$ be an increasing right-continuous process with values in $\{1, 2, \ldots\} \cup \{\infty\}$. Let $0 \leq q_j < \infty$ for all $j \geq 0$. Then the following are equivalent:
	\begin{enumerate}[\normalfont(a)]
		\item \emph{(Jump chain/holding time definition)} Conditional on $X_s = i$, the holding times $S_1, S_2, \ldots$ are independent exponential with rates $q_i, q_{i+1}, \ldots$ respectively, and the jump chain is given by $Y_n = i+n$ for all $n$.
		\item \emph{(Infinitesimal definition)} For all $t, h \geq 0$, conditional on $X_t = i$, the process $(X_{t+h})_{h \geq 0}$ is independent of $(X_s \mid s \leq t)$ and as $h \downarrow 0$ uniformly in $t$,
			\begin{align*}
				\mathbb{P}(X_{t+h} = i \mid X_t = i) &= 1 - q_i h + o(h), \\
				\mathbb{P}(X_{t+h} = i+1 \mid X_t = i) &= q_i h + o(h).
			\end{align*}
		\item \emph{(Transition probability definition)} For all $n = 0, 1, 2, \ldots$ and all times $0 \leq t_0 \leq t_1 \leq \cdots \leq t_{n+1}$, and all states $i_0, i_1, \ldots, i_{n+1}$,
			\[
			\mathbb{P}(X_{t_{n+1}} = i_{n+1} \mid X_0 = i_0, \ldots, X_{t_n} = i_n) = P_{i_n, i_{n+1}} (t_{n+1} - t_n)
			,\]
			where $(P_{i,j}(t))$ is the unique solution to the equation
			\[
			P_{i,j}'(t) = q_{j-1}P_{i,j-1}(t) - q_jP_{i,j}(t)
			.\]
	\end{enumerate}
\end{theorem}

As in the Poisson process,
\[
P_{i,j}(t+h) = P_{i,j-1}(t) q_{j-1} h + P_{i,j}(t) (1 - q_j h) + o(h).
\]
Existence and uniqueness follows since for $i = j$,
\[
P_{i,i}'(t) = -q_i P_{i,i}(t)
,\]
and $P_{i,i}(0) = 1$, so $P_{i,i}(t) = e^{-q_i t}$, so by induction the unique solution for $P_{i,j}(t)$ exists.

Also note that we can write $P'(t) = P(t)Q$ where $P(t) = (P_{ij}(t))$ and
\[
Q =
\begin{pmatrix}
	-q_1 & q_1 & 0 & 0 & \cdots \\
	0 & -q_2 & q_2 & 0 & \cdots \\
	0 & 0 & -q_3 & q_3 & \cdots \\
	0 & 0 & 0 & q_4 & \cdots \\
	\vdots & \vdots & \vdots & \vdots & \ddots
\end{pmatrix}
\]

\newpage

\section{Q-matrix and Construction of Markov Processes}
\label{sec:q_matrix_and_construction_of_markov_processes}

\begin{definition}
	$Q = (q_{ij})_{i,j \in I}$ is called a $Q$\emph{-matrix}\index{$Q$-matrix} if
	\begin{enumerate}[(a)]
		\item $0 \leq -q_{ii} < \infty$ for all $i \in I$,
		\item $0 \leq q_{ij} < \infty$ for all $i \neq j \in I$,
		\item $\sum_{j} q_{ij} = 0$ for all $i \in I$.
	\end{enumerate}
	We write $q_i = -q_{ii} = \sum_{j \neq i}q_{ij}$ for all $i \in I$.

	Given a $Q$-matrix $Q$, we define a jump matrix $P$\index{jump matrix} as follows: for $x \neq y$ with $q_x \neq 0$, set $p_{xy} = \frac{q_{xy}}{q_x}$ and $p_{x x} = 0$. If $q_x = 0$, set $p_{xy} = \mathbbm{1}(x = y)$.
\end{definition}

\begin{exbox}
	If
	\[
	Q =
	\begin{pmatrix}
		-1 & 1 & 0 \\
		1 & -2 & 1 \\
		2 & 1 & -1
	\end{pmatrix}
	,\]
	then
	\[
	P =
	\begin{pmatrix}
		0 & 1 & 0 \\
		\frac{1}{2} & 0 & \frac{1}{2} \\
		\frac{2}{3} & \frac{1}{3} & 0
	\end{pmatrix}
	.\]
\end{exbox}

Note that $P$ is a stochastic matrix.

\begin{definition}
	Let $Q$ be a $Q$-matrix and $\lambda$ be a probability measure on $I$. Then a (minimal) random process $X$ is a \emph{Markov process}\index{Markov process} with initial distribution $\lambda$ and infinitesimal generator $Q$ if:
	\begin{enumerate}[(a)]
		\item The jump chain $Y_n = X_{J_n}$ is a discrete-time Markov chain with $Y_0 \sim \lambda$ and transition matrix $P$.
		\item Conditional on $Y_0, Y_1, \ldots, Y_n$, the holding times $S_1, S_2, \ldots, S_{n+1}$ are independent with $S_i \sim \Exp(q_{Y_{i-1}})$ for $i = 1, 2, \ldots, n+1$.
	\end{enumerate}
	We write $X \sim \Mkv(\lambda, Q)$.
\end{definition}

\begin{exbox}
	Birth processes are $\Mkv(\lambda, Q)$ with $I = \mathbb{N}$ and
\[
Q =
\begin{pmatrix}
	-q_1 & q_1 & 0 & 0 & \cdots \\
	0 & -q_2 & q_2 & 0 & \cdots \\
	0 & 0 & -q_3 & q_3 & \cdots \\
	0 & 0 & 0 & q_4 & \cdots \\
	\vdots & \vdots & \vdots & \vdots & \ddots
\end{pmatrix}
\]
Note that
\[
P =
\begin{pmatrix}
	0 & 1 & 0 & 0 & \cdots \\
	0 & 0 & 1 & 0 & \cdots \\
	0 & 0 & 0 & 1 & \cdots \\
	0 & 0 & 0 & 0 & \cdots \\
	\vdots & \vdots & \vdots & \vdots & \ddots
\end{pmatrix}
\]
We know exactly that $Y_n = Y_0 + n$.
\end{exbox}

\subsection{Constructions of Markov continuous processes}
\label{sub:constructions_of_markov_continuous_processes}

\begin{enumerate}[1.]
	\item $(Y_n)$ is a discrete time Markov chain, $Y_0 \sim \lambda$ with transition matrix $P$.

		$(T_i)$ are iid $\Exp(1)$, independent of $Y$, and set
		\[
		S_n = \frac{T_n}{q_{Y_{n-1}}}, \qquad J_n = \sum_{i = 1}^{n} S_i
		.\]
		Then set $X_t = Y_n$ if $J_n \leq t < J_{n+1}$, and $X_t = \infty$ otherwise.
	\item Let $(T_n^{y})$ be iid $\Exp(1)$ random variables, with $Y_0 \sim \lambda$, and inductively define $Y_n, S_n$ as, if $Y_n = x$, then for $y \neq x$, let
			\[
			S_{n+1}^{y} = \frac{T_{n+1}^{y}}{q_{xy}} \sim \Exp(q_{xy}), \qquad S_{n+1} = \inf_{y \neq x} S_{n+1}^{y}.
			\]
			If $S_{n+1} = S_{n+1}^{z}$ for some random $z$, then take $Y_{n+1} = z$, if $q_x > 0$. If $q_x = 0$, then take $Y_{n+1} = x$.
		\item For $x \neq y$, let $(N_t^{x,y})$ be independent Poisson processes with rates $q_{xy}$ respectively. Let $Y_0 \sim \lambda$, $J_0 = 0$ and define inductively
			\[
				J_{n+1} = \inf \{ t > J_n \mid N_t^{Y_n,y} \neq N_{J_n}^{Y_n,y}\}
			,\]
			and define
			\[
			Y_{n+1}=
			\begin{cases}
				y & J_{n+1} < \infty, N_{J_{n+1}}^{Y_n,Y} \neq N_{J_n}^{Y_n,y}, \\
				Y_n & J_{n+1} = \infty.
			\end{cases}
			\]
\end{enumerate}

For birth processes, we characterized when non-explosion happens. In general, we only give a sufficient condition.

\begin{theorem}
	Let $X$ be $\Mkv(\lambda, Q)$ on $I$. Then $\mathbb{P}(\zeta = \infty) = 1$ if any of the following holds:
	\begin{enumerate}[\normalfont(a)]
		\item $I$ is finite.
		\item $\sup_{x \in I} q_x < \infty$.
		\item $X_0 = x$ and $x$ is recurrent for the jump chain $Y$.
	\end{enumerate}
\end{theorem}

\begin{proofbox}
	Note (a) implies (b), so it is enough to prove for (b).

	Set $q = \sup_{x \in I} q_x < \infty$. Then the holding times
	\[
	S_n \geq \frac{T_n}{q}
	,\]
	where $(T_i) \sim \Exp(1)$. Then
	\[
	\zeta = \sum_{n = 1}^{\infty} S_n \geq \frac{1}{q} \sum_{n = 1}^{\infty} T_n = \infty
	\]
	with probability one. Hence $\mathbb{P}(\zeta = \infty) = 1$.

	For (c), let $(N_i)$ be the times when the jump chain $Y_i$ visits $x$. By the strong law of large numbers,
	\[
	\zeta \geq \sum_{i = 1}^{\infty} S_{N_i+1} = \sum_{i = 1}^{\infty} \frac{T_{N_i+1}}{q_{N_i}} = \frac{1}{q_x} \sum_{i = 1}^{\infty} T_{N_i + 1} = \infty
	.\]
	Hence $\mathbb{P}(\zeta = \infty) = 1$.
\end{proofbox}

\begin{exbox}
	Let $I = \mathbb{Z}$, and $q_{i,i+1} = q_{i,i-1} = 2^{|i|}$. Then $p_{i,i+1} = p_{i,i-1} = \frac{1}{2}$. So the jump chain $Y$ is the simple random walk on $\mathbb{Z}$, which is recurrent. Hence $X$ is non-explosive.

	Now consider $I = \mathbb{Z}$, where $q_{i,i+1} = 2^{|i|+1}$, and $q_{i,i-1} = 2^{|i|}$. Then $Y$ is a simple random walk with $q_{i,i+1} = \frac{2}{3}$, and $q_{i,i-1} = \frac{1}{3}$. This is transient, so we cannot use the theorem. Instead,
	\begin{align*}
		\mathbb{E}[\zeta] &= \mathbb{E}\Biggl[ \sum_{n = 1}^{\infty} S_n \Biggr] = \sum_{j \in \mathbb{Z}} \mathbb{E}\Biggl[ \sum_{k = 1}^{V_j} S_{N_k^{j} + 1} \Biggr] \\
				  &= \sum_{j \in \mathbb{Z}} \mathbb{E}[V_j] \mathbb{E}[S_{N_1^{j} + 1}] = \sum_{j \in \mathbb{Z}} \mathbb{E}[V_j] \frac{1}{q_j} \\
				  &= \sum_{j \in \mathbb{Z}} \frac{1}{3 \cdot 2^{|i|}} \mathbb{E}[V_j].
	\end{align*}
	Note that $\mathbb{E}[V_j] \leq 1 + \mathbb{E}_j[V_j] = 1 + \mathbb{E}_0[V_0] = c < \infty$ as the jump chain is transient. Hence
	\[
	\mathbb{E}[\zeta] = \sum_{j \in \mathbb{Z}} \frac{1}{3 \cdot 2^{|j|}} \mathbb{E}[V_j] \leq \sum_{j \in \mathbb{Z}} \frac{c}{3 \cdot 2^{|j|}} < \infty
	.\]
	Therefore, $\mathbb{P}(\zeta < \infty) = 1$, so the process is explosive.
\end{exbox}

\begin{theorem}
	Let $X$ be $\Mkv(\lambda, Q)$ and $T$ a stopping time. Then conditional on $T < \zeta$, and $X_T = x$, the process $(X_{T+t})_{t \geq 0}$ is $\Mkv(\delta_x, Q)$ and independent of $(X_s)_{s \leq T}$.
\end{theorem}

This is not proved: it uses measure theory. A reference can be found in James Norris notes.

\subsection{Kolmogorov's Forward and Backward Equations}
\label{sub:kolmogorovs_forward_and_backward_equations}

We work with a countable state space $I$.

\begin{theorem}
	Let $X$ be a minimal right continuous process with values in a countable set $I$. Let $Q$ be a $Q$-matrix with jump matrix $P$. Then the following are equivalent:
	\begin{enumerate}[\normalfont(a)]
		\item $X$ is a continuous time Markov chain with generator $Q$.
		\item For all $n \geq 0$, $0 \leq t_0 \leq \cdots \leq t_n \leq t_{n+1}$ and all states $x_0, \ldots, x_{n+1} \in I$,
			\[
			\mathbb{P}(X_{t_{n+1}} = x_{n+1} \mid X_{t_n} = x_n, \ldots, X_{t_0} = x_0) = P_{x_n,x_{n+1}}(t_{n+1} - t_n)
			,\]
			where $(P(t)) = (P_{xy}(t))$ is the minimal non-negative solution to the backward equation
			\[
			P'(t) = Q P(t), \qquad P(0) = I
			.\]
			Minimality means that if $\tilde P$ is another non-negative solution to the backward equation, then
			\[
			P_{xy}(t) \leq \tilde P_{xy}(t)
			.\]
			In fact, if the chain is non-explosive, the solution is unique.
		\item $P(t)$ is also the minimal non-negative solution to the forwards equation
			\[
			P'(t) = P(t)Q, \qquad P(0) = I
			.\]
	\end{enumerate}
\end{theorem}

We will show (a) is equivalent to (b), and skip the proof of the equivalence of (c). The proof of this is found in Norris' notes.

\begin{proofbox}
	To show (a) implies (b), let $(J_n)$ denote the jump times. Then conditioning on the first jump time,
	\[
		\mathbb{P}_x(X_t = y, J_1 > t) = \mathbbm{1}(x = y) e^{-q_xt}
	.\]
	Integrating on the values of $J_1 < t$ and using the independence of the jump chain to the values of the holding times, for $z \neq x$,
	\begin{align*}
		\mathbb{P}_x(X_t = y, J_1 \leq t, X_{J_1} = z) &= \int_{0}^{t} q_x e^{-q_x s} \frac{q_{xz}}{q_{x}} P_{zy}(t-s) \diff s \\
							       &= \int_{0}^{t} e^{-q_x s} q_{xz} P_{zy}(t-s) \diff s
	\end{align*}
	Summing over all $z \neq x$,
	\begin{align*}
		\mathbb{P}_x(X_t = y, J_1 \leq t) &= \int_{0}^{t} \sum_{z \neq x} e^{-q_x s} q_{xz} P_{zy}(t - s) \diff s.
	\end{align*}
	Hence
	\[
		P_{xy}(t) = \mathbb{P}_x(X_t = y) = e^{-q_x t} \mathbbm{1}(x = y) + \int_{0}^{t} \sum_{z \neq x} e^{-q_x s} q_{xz} P_{zy}(t - s) \diff s
	.\]
	Making a change of variable $u = t-s$, we get
	\[
		e^{q_x t} P_{xy}(t) = \mathbbm{1}(x=y) + \int_{0}^{t} \sum_{z \neq x} e^{q_x u} q_{xz} P_{zy}(u) \diff u
	.\]
	Thus $P_{xy}(t)$ is a continuous function in $t$, and hence
	\[
	\sum_{z \neq x} e^{q_x u} q_{xz} P_{zy}(u)
	\]
	is a series of continuous functions, and is also uniformly convergent, and hence continuous. Therefore the integral is differentiable, and
	\[
	e^{q_xt}(q_x P_{xy}(t) + P_{xy}'(t)) = \sum_{z \neq x} e^{q_xt} q_{xz} P_{zy}(t)
	.\]
	Thus
	\[
	P_{xy}'(t) = \sum_{z} q_{xz} P_{zy}(t)
	,\]
	or $P'(t) = QP(t)$.

	To show minimality, let $\tilde P$ be another non-negative solution of the backward equation. We will show
	\[
	P_{xy}(t) \leq \tilde P_{xy}(t)
	,\]
	for all $x, y, t$. As before,
	\begin{align*}
		\mathbb{P}_x(X_t = &y, t < J_{n+1}) = \mathbb{P}_x(X_t = y, J_1 > t) + \mathbb{P}_x(X_t = y, J_1 \leq t < J_{n+1}) \\
						   &= e^{-q_x t}\mathbbm{1}(x = y) + \sum_{z \neq x} \int_{0}^{t} q_x e^{-q_x s} \frac{q_{xz}}{q_x} \mathbb{P}_z (X_{t-s} = y, t-s < J_n) \diff s.
	\end{align*}
	Now as $\tilde P$ satisfies the backwards equation, we get as before
	\[
		\tilde P_{xy}(t) = e^{-q_x t} \mathbbm{1}(x = y) + \sum_{z \neq x} \int_{0}^{t} e^{-q_x s} q_{xz} \tilde P_{zy}(t-s) \diff s
	.\]
	Now we prove by induction that
	\[
	\mathbb{P}_x(X_t = y, t < J_n) \leq \tilde P_{xy}(t)
	,\]
	for all $n$. For $n = 1$,
	\[
		e^{-q_x t}\mathbbm{1}(x = y) \leq \tilde P_{xy}(t)
	,\]
	by our equation for $\tilde P_{xy}(t)$. Assuming for $n$, then for $n+1$,
	\begin{align*}
		\mathbb{P}_x(X_t = y, t < J_{n+1}) \leq e^{-q_x t} \mathbbm{1}(x = y) + \sum_{z \neq x} \int_{0}^{t} q_x e^{-q_x s} P_{zy}(t-s) \diff s = \tilde P_{xy}(t).
	\end{align*}
	Hence,
	\[
	\mathbb{P}_x(X_t = y, t < \zeta) = \lim_{n \to \infty}\mathbb{P}_x(X_t = y, t < J_n) \leq \tilde P_{xy}(t)
	.\]
	Using minimality,
	\[
	P_{xy}(t) = \mathbb{P}_x(X_t = y) = \mathbb{P}_x(X_t = y, t < \zeta) \leq \tilde P_{xy}(t)
	.\]
\end{proofbox}

\subsection{Finite State Spaces}
\label{sub:finite_state_spaces}

\begin{definition}
	If $A$ is a finite-dimension square matrix, its \emph{matrix exponential}\index{matrix exponential} is given by
	\[
	e^{A} = \sum_{k = 0}^{\infty} \frac{A^{k}}{k!} = I + A + \frac{A^2}{2!} + \cdots
	.\]
\end{definition}

\begin{proposition}
	For any $r \times r$ matrix $A$, the exponential $e^{A}$ is an $r \times r$ matrix, and if $A_1, A_2$ commute, then
	\[
	e^{A_1 + A_2} = e^{A_1} e^{A_2}
	.\]
\end{proposition}

\begin{proposition}
	Let $Q$ be a $Q$-matrix on a finite set $I$, and let
	\[
	P(t) = e^{tQ}
	.\]
	Then,
	\begin{enumerate}[\normalfont(i)]
		\item $P(t+s) = P(t)P(s)$ for all $s, t$.
		\item $(P(t))$ is the unique solution to the forward equation $P'(t) = P(t)Q$, $P(0) = I$.
		\item $(P(t))$ is the unique solution to the backward equation $P'(t) = QP(t)$, $P(0) = I$.
		\item For $k = 0, 1, 2, \ldots$ 
			\[
			\biggl( \frac{\diff}{\diff t} \biggr)^{k} P(t) \biggr|_{t=0} = Q^{k}
			.\] 
	\end{enumerate}
\end{proposition}

\begin{proofbox}
	\begin{enumerate}[(i)]
		\item Since $tQ$ and $sQ$ commute,
			\[
			P(t+s) = e^{(t+s)Q} = e^{tQ}e^{sQ} = P(t)P(s)
			.\]
		\item The sum in $e^{tQ}$ has infinite radius of convergence, hence we can differentiate term by term to get
			\begin{align*}
				\frac{\diff}{\diff t} P(t) &= \frac{\diff}{\diff t} e^{tQ} = \frac{\diff}{\diff t} \sum_{k = 0}^{\infty} \frac{(tQ)^{k}}{k!} = \sum_{k = 0}^{\infty} \frac{\diff}{\diff t} \frac{t^{k}Q^{k}}{k!} \\
							   &= \sum_{k=1}^{\infty} \frac{kt^{k-1}}{k!} Q^{k} = \sum_{k = 1}^{\infty} \frac{t^{k-1}}{(k-1)!} Q^{k-1}Q = Q e^{tQ} = P(t) Q.
			\end{align*}
		\item Similarly $P'(t) = QP(t)$.
	\end{enumerate}
	We get that
	\[
	\frac{\diff}{\diff t} e^{tQ} = Q e^{tQ} = e^{tQ}Q
	.\]
	For uniqueness, if $\tilde P$ is another solution to the forward equation, then $\tilde P'(t) = Q \tilde P(t)$ and $\tilde P(0) = I$, then
	\begin{align*}
		\frac{\diff}{\diff t} \biggl( \tilde P(t) e^{-t Q} \biggr) &= \tilde P'(t) e^{-tQ} + \tilde P(t) \frac{\diff}{\diff t} e^{-tQ} \\
									   &= \tilde P(t) Qe^{-tQ} + \tilde P(t)(-Q e^{-tQ}) = 0,
	\end{align*}
	so $\tilde P(t) e^{-tQ}$ is a constant matrix. Since $\tilde P(0) e^{0} = I$, we get $\tilde P(t) = e^{tQ}$.

	Similarly, if $\tilde P$ is a solution to the backward equation, we can find $e^{-tQ} \tilde P(t) = I$.

	(iv) is obtained by differentiating term-by-term $k$ times.
\end{proofbox}

\begin{exbox}
	Let
	\[
	Q =
	\begin{pmatrix}
		-2 & 1 & 1 \\
		1 & -1 & 0 \\
		2 & 1 & -3
	\end{pmatrix}
	.\]
	To find $P_{11}(t)$, we can diagonalise $Q = PDP^{-1}$, where
	\[
	D =
	\begin{pmatrix}
		\lambda_1 & 0 & 0 \\
		0 & \lambda_2 & 0 \\
		0 & 0 & \lambda_3
	\end{pmatrix}
	,\]
	to get
	\begin{align*}
		e^{tQ} &= \sum_{k = 01}^{\infty} \frac{t^{k} Q^{k}}{k!} = \sum_{k = 0}^{\infty} t^{k} \frac{P D^{k} P^{-1}}{k!} \\
		       &= P 
		       \begin{pmatrix}
			       e^{t \lambda_1} & 0 & 0 \\
			       0 & e^{t \lambda_2} & 0 \\
			       0 & 0 & e^{t \lambda_3}
		       \end{pmatrix}
		       P^{-1},
	\end{align*}
	which gives $P_{11}(t) = a e^{t \lambda_1} + b e^{t \lambda_2} + c e^{t \lambda_3}$. To find the constants $a, b, c$, note $P_{11}(0) = 1$, $P_{11}'(0) = q_{11}$ and $P_{11}''(0) = Q^2_{11}$.
\end{exbox}

\begin{theorem}
	Let $I$ be a finite state space and $Q$ be a matrix. Then, it is a $Q$-matrix if and only if $P(t) = e^{tQ}$ is a stochastic matrix for all $t \geq 0$.
\end{theorem}

\begin{proofbox}
	For $t \downarrow 0$, $e^{tQ} = I + tQ + \mathcal{O}(t^2)$. Hence, for $x \neq y$, $q_{xy} \geq 0$ if and only if $P_{xy}(t) \geq 0$ for all $t \geq 0$ sufficiently small.

	Since $P(t) = P(t/n)^{n}$ for all $n$, we get $q_{xy} \geq 0$ if and only if, $p_{xy}(t) \geq 0$ for all $t \geq 0$.

	Assume now that $Q$ is a $Q$-matrix, so $\sum_y q_{xy} = 0$ for all $x$. Then,
	\begin{align*}
		\sum_y Q^{n}_{xy} &= \sum_y \sum_z Q^{n-1}_{xz} Q_{zy} = \sum_{z} Q^{n-1}_{xz} \sum_y Q_{zy} = 0.
	\end{align*}
	Hence, since
	\[
	P_{xy}(t) = \delta_{xy} + \sum_{k=1}^{\infty} \frac{t^{k}}{k!} Q^{k}_{xy}
	,\]
	we must have
	\[
	\sum_{y} P_{xy}(t) = 1 + \sum_{k = 1}^{\infty} \frac{t^{k}}{k!} \sum_y Q^{k}_{xy} = 1
	,\]
	proving $P(t)$ is a stochastic matrix.

	Assuming that $P(t)$ is a stochastic matrix, then as
	\[
	Q = \frac{\diff}{\diff t} \biggr|_{t = 0}P(t)
	,\]
	then
	\[
	\sum_y  q_{xy} = \frac{\diff}{\diff t}\biggr|_{t = 0} \sum_y P_{xy}(t) = 0
	,\]
	hence $Q$ is a $Q$-matrix.
\end{proofbox}

\begin{theorem}
	Let $X$ be a right-continuous process with values in a finite set $I$, and let $Q$ be a $Q$-matrix on $I$. Then the following are equivalent:
	\begin{enumerate}[\normalfont(a)]
		\item The process is Markov with generator $Q$ (written $\Mkv(Q)$.
		\item \emph{Infinitesimal definition}. Conditional on $X_s = x$, the process $(X_{s+t})_{t \geq 0}$ is independent of $(X_{r})_{r \leq s}$, and uniformly in $t$ as $h \downarrow 0$,
			\[
				\mathbb{P}(X_{t+h} = y \mid X_t = x) = \mathbbm{1}(x = y) + q_{xy}h + o(h)
			.\]
		\item For all $n \geq 0$, $0 \leq t_0 \leq \dots \leq t_n$ and all states $x_0, \dots, x_n$,
			\[
			\mathbb{P}(X_{t_n} = x_n \mid X_{t_0} = x_0, \ldots, X_{t_{n-1}} = x_{n-1}) = P_{x_{n-1}x_{n}}(t_n - t_{n-1})
			,\]
		where $(P_{xy}(t))$ is the solution to the forward equation
		\[
		P'(t) = P(t) Q, \qquad P(0) = I
		.\]
	\end{enumerate}
\end{theorem}

\begin{proofbox}
	We have shown the equivalence of (a) and (c), so it is enough to show the equivalence of (b) and (c).

	To show (c) implies (b), we know $P(t) = e^{tQ}$ is the solution to the forward equation. As $t \downarrow 0$, $P(t) = I + tQ + \mathcal{O}(t^2)$, thus for all $t > 0$ and as $h \downarrow 0$, for all $x$ and $y$,
	\[
	\mathbb{P}(X_{t+h} = y \mid X_t = x) = \mathbb{P}(X_h = y \mid X_0 = x) = P_{xy}(h) = \delta_{xy} + h q_{xy} + o(h)
	.\]

	To show (b) implies (c), note
	\begin{align*}
		P_{xy}(t+h) &= \sum_z P_{xz}(t) \cdot (\mathbbm{1}(z = y) + q_{zy} h + o(h)).
	\end{align*}
	So rearranging,
	\[
	\frac{P_{xy}(t+h) - P_{xy}(t)}{h} = \sum_z P_{xz}(t) q_{zy} + o(1)
	.\]
	As $h \downarrow 0$,
	\[
	P_{xy}'(t) = \sum_{z} P_{xz}(t) q_{zy} = P(t) Q
	.\]
\end{proofbox}

\newpage

\section{Qualitative Properties of Continuous Time Markov Chains}
\sectionmark{Qualitative Properties}
\label{sec:qualitative_properties_of_continuous_times_markov_chains}

We consider minimal chains, and countable state spaces.

\subsection{Class Structure}
\label{sub:class_structure}

\begin{definition}
	For states $x, y \in I$, we write $x \to y$ if
	\[
		\mathbb{P}_x(X_t = y \text{ for some } t > 0) > 0
	.\]
	We write $x \leftrightarrow y$ if $x \to y$ and $y \to x$.

	We can define \emph{communicating classes}\index{communicating classes}, \emph{irreducibility}\index{irreducible}, \emph{closed class}\index{closed class} and \emph{absorbing states}\index{absorbing states} exactly as in the discrete-time case.
\end{definition}

\begin{proposition}
	Let $X$ be $\Mkv(Q)$ with transition semigroup $(P(t))_{t \geq 0}$. For any two states $x, y \in I$, the following are equivalent:
	\begin{enumerate}[\normalfont(a)]
		\item $x \to y$.
		\item $x \to y$ for the jump chain.
		\item $q_{x_0x_1}\cdots q_{x_{n-1}x_n} > 0$ for some $x = x_0$, $x_1, \dots, x_{n-1}$, $x_n = y$.
		\item $P_{xy}(t) > 0$ for all $t > 0$.
		\item $P_{xy}(t) > 0$ for some $t > 0$.
	\end{enumerate}
\end{proposition}

\begin{proofbox}
	Clearly (d) implies (e) implies (a) implies (b).

	To show (b) implies (c), since $x \to y$ for the jump chain, there exists $x_0 = x, x_1, \dots, x_n = y \in I$ such that
	\[
	P_{x_0x_1}P_{x_1x_2} \cdots P_{x_{n-1}x_n} > 0
	.\]
	By the definition of the jump chain, we immediately get
	\[
	q_{x_0x_1} q_{x_1 x_2} \cdots q_{x_{n-1}x_n} > 0
	.\]
	Now to show (c) implies (d), for any two states $w, z$ with $q_{wz} > 0$, and for any $t > 0$,
	\[
	P_{wz}(t) \geq \mathbb{P}_{\omega} (J_1 \leq t, Y_1 = z, S_2 > t) = (1 - e^{-q_w t}) \frac{q_{wz}}{q_w} e^{-q_zt} > 0
	.\]
	Hence if $q_{wz} > 0$, $P_{wz}(t) > 0$. Therefore if (c) holds then $P_{x_ix_{i+1}}(t) > 0$ for all $t$, hence
	\[
	P_{xy}(t) \geq P_{x_0x_1}\biggl( \frac{t}{n} \biggr) P_{x_1x_2}\biggl( \frac{t}{n} \biggr)\cdots P_{x_{n-1}x_n}\biggl( \frac{t}{n} \biggr) > 0
	.\] 
\end{proofbox}

\subsection{Hitting Times}
\label{sub:hitting_times}

Let $Y$ be the jump chain associated with $X$, and $A \subset I$. Se $T_A = \inf\{t > 0 \mid X_t \in A\}$ be the \emph{hitting time}\index{hitting time}, and $H_A = \inf\{n \geq 0 \mid Y_n \in A\}$.

We also define the \emph{hitting probability}\index{hitting probability} $h_a(x) = \mathbb{P}_x(T_A < \infty)$, and \emph{mean hitting probability}\index{mean hitting times} $k_A(x) = \mathbb{E}[T_A]$.

Note the hitting probability of $X$ is the same as that for $Y$, but the mean hitting times will differ.

\begin{theorem}
	$(h_A(x))_{x \in I}$ and $(k_{A}(x))_{x \in I}$ are the minimal non-negative solutions to
	\[
	\begin{cases}
		h_A(x) = 1 & x \in A, \\
		Qh_A(x) = \sum_{y} q_{xy} h_A(y) = 0 & x \not \in A,
	\end{cases}
	\]
	\[
	\begin{cases}
		k_A(x) = 0 & x \in A, \\
		Qk_A(x) = \sum_y q_{xy} k_A(y) = -1 & x \not \in A,
	\end{cases}
	\]
	assuming $q_x > 0$ for all $x \not \in A$.
\end{theorem}

\begin{proofbox}
	For $h$, the hitting probability is the same as those for the jump chain, so $h_A(x) = 1$ for all $x \in A$, and
	\[
	h_A(x) = \sum_{y \neq x} h_A(y) p_{xy} = \sum_{y \neq x} h_A(y) \frac{q_{xy}}{q_{x}}
	.\]
	Hence we can rewrite this as
	\[
	\sum_{y} h_A(y) q_{xy} = 0
	.\]
	Now we consider the mean hitting times, $k$. If $x \in A$, then $T_A = 0$ so $k_A(x) = 0$. Let $x \not \in A$. Then $J_1 < T_A$, and hence
	\begin{align*}
		k_A(x) &= \mathbb{E}_x[T_A] = \mathbb{E}_x[J_1] + \mathbb{E}_x[T_A - J_1] = \mathbb{E}_x[J_1] + \sum_{y \neq x} \mathbb{E}_x[T_a - J_1 \mid Y_1 = y] p_{xy} \\
		       &= \frac{1}{q_x} + \sum_{y \neq x} \mathbb{E}_y[T_A] \frac{q_{xy}}{q_x} \\
		       &= \frac{1}{q_x} + \sum_{y \neq x} k_A(y) \frac{q_{xy}}{q_x}.
	\end{align*}
	Rearranging, we get
	\[
	\sum_{y} q_{xy}k_A(x) = -1
	.\]
	The minimality of the solutions is exactly as in the discrete time chain.
\end{proofbox}

\subsection{Recurrence and Transience}
\label{sub:recurrence_and_transience}

\begin{definition}
	The state $x$ is called \emph{recurrent}\index{recurrence} if
	\[
		\mathbb{P}(\sup \{t \mid X_t = x\} = \infty) = 1
	.\]
	The state $x$ is called \emph{transient}\index{transience} if
	\[
		\mathbb{P}(\sup \{t \mid X_t = x\} = \infty) = 0
	.\]
\end{definition}

\begin{remark}
	If $X$ explodes with positive probability starting from $x$, i.e. if $\mathbb{P}(\zeta < \infty) > 0$, then
	\[
		\mathbb{P}( \sup\{t \mid X_t = x\} < \infty) \geq \mathbb{P}(\zeta < \infty) > 0
	,\]
	so $x$ cannot be recurrent.
\end{remark}

\begin{theorem}
	Let $X$ be $\Mkv(Q)$ with jump chain $Y$. Then,
	\begin{enumerate}[\normalfont(a)]
		\item If $x$ is recurrent for $Y$, then $x$ is recurrent for $X$.
		\item If $x$ is transient for $Y$, then $x$ is transient for $X$.
		\item Every state is either recurrent or transient.
		\item Recurrence and transience are class properties.
	\end{enumerate}
\end{theorem}

\begin{proofbox}
	Note that (a) and (b) and results for discrete chains imply (c) and (d).

	For (a), suppose $x$ is recurrent for $Y$ and $X_0 = x$. Then $X$ is not explosive, i.e. $\mathbb{P}(\zeta = \infty) = 1$, and $J_n \to \infty$ with probability one, starting from $x$. Since $X_{J_n} = Y_n$ for all $n$, and $Y$ visits $x$ infinitely many times,
	\[
		\mathbb{P}(\sup \{t \mid X_t = x\} = \infty) = 1
	.\]
	For (b), if $x$ is transient for $Y$, then $q_x > 0$. Also, there is almost surely a last visit to $x$ for $Y$, i.e. $N = \sup\{n \mid Y_n = x\} < \infty$.

	Also, $J_{N+1} < \infty$ almost surely, as $q_x > 0$, and if $t \in \{S \mid X_s = x\}$, then $t < J_{N+1}$. Hence
	\[
		\sup\{s \mid X_s = x\} \leq J_{N+1} < \infty
	.\]
\end{proofbox}

We have an analogue for the discrete time result on recurrence and transience, namely
\[
	\sum_{n} p_{x x}(n) = \infty \iff x \text{ is recurrent}
.\]
\begin{theorem}
	$x$ is recurrent for $X$ if and only if
	\[
	\int_{0}^{\infty} p_{x x}(t) \diff t = \infty
	.\]
\end{theorem}

\begin{proofbox}
	If $q_x = 0$, then $x$ is absorbing, hence recurrent, and $p_{x x}(t) = 1$, so the integral is infinite. Assume $q_x > 0$. Then,
	\begin{align*}
		\int_{0}^{\infty}p_{x x}(t) \diff t &= \int_{0}^{\infty} \mathbb{E}_x[\mathbbm{1}(X_t = x)] \diff t \\
						    &= \mathbb{E}_x \Biggl[ \int_{0}^{\infty} \mathbbm{1}(X_t = x) \diff t \Biggr] \\
						    &= \mathbb{E}_x \Biggl[ \sum_{n = 0}^{\infty} \mathbbm{1}(Y_n = x)S_{n+1} \Biggr] \\
						    &= \sum_{n = 0}^{\infty} \mathbb{E}_x [\mathbbm{1}(Y_n = x) S_{n+1}] \\
						    &= \sum_{n = 0}^{\infty} \mathbb{P}_x (Y_n = x) \mathbb{E}_x[S_{n+1} \mid Y_n = x] \\
						    &= \sum_{n = 0}^{\infty} p_{x x}(n) \frac{1}{q_x} = \frac{1}{q_x} \sum_{n = 0}^{\infty} p_{x x}(n).
	\end{align*}
	So the result follows from the discrete time case and the previous theorem.
\end{proofbox}

\subsection{Invariant Distributions}
\label{sub:invariant_distributions}

For a discrete Markov chain $Y$, $\pi$ is an \emph{invariant measure}\index{invariant measure} for $Y$ if and only if $\pi P = \pi$. Moreover if $\sum_i \pi_i = 1$, then $\pi$ is called an \emph{invariant distribution}\index{invariant distribution}. If $Y_0 \sim \pi$, then $Y_n \sim \pi$ for $n \geq 1$.

In fact recall:
\begin{theorem}
	If $Y$ is a discrete time Markov chain, irreducible and recurrent. Then,
	\[
		\nu^{x}(y) = \mathbb{E}_x \Biggl[ \sum_{n = 0}^{H_x - 1} \mathbbm{1}(Y_n = y) \Biggr]
	,\]
	where $H_x = \inf \{n \geq 1 \mid Y_n = x\}$. THen $\nu^{x}$ is an invariant measure, and $0 < \nu^{x}(y) < \infty$ for all $y$, with $\nu^{x}(x) = 1$.
\end{theorem}

\begin{theorem} 
	Let $Y$ be irreducible. If $\lambda$ is any invariant measure with $\lambda(x) = 1$, then
	\[
	\lambda(y) \geq \nu^{x}(y)
	.\]
	If $Y$ is recurrent then $\lambda(y) = \nu^{x}(y)$.
\end{theorem}

\begin{definition}
	Let $X \sim \Mkv(Q)$ and let $\lambda$ be a measure. It is calledn \emph{invariant} or \emph{infinitesimally invariant}\index{invariant} if $\lambda Q = 0$.
\end{definition}

\begin{lemma}
	If $|I|$ is finite, then $\lambda Q = 0$ if and only if $\lambda P(s) = \lambda$ for all $s \geq 0$.
\end{lemma}

\begin{proofbox}
	If $|I|$ is finite, then $P(s) = e^{sQ}$, so if $\lambda Q = 0$, then
	\begin{align*}
		\lambda P(s) &= \lambda e^{sQ} = \lambda \sum_{k = 0}^{\infty} \frac{(sQ)^{k}}{k!} \\
			     &= \lambda I + \lambda (sQ) + \lambda \frac{(sQ)^2}{2!} + \lambda \frac{(sQ)^3}{3!} + \cdots \\
			     &= \lambda + s \lambda Q + s^2 \frac{\lambda Q^2}{2!} + s^3 \frac{\lambda Q^3}{3!} + \cdots \\
			     &= \lambda.
	\end{align*}
	Now if $\lambda P(s) = \lambda$ for all $s$, then since
	\[
	Q = \frac{\diff}{\diff s} P(s) \biggr|_{s = 0}
	,\]
	then
	\[
	\lambda Q = \frac{\diff}{\diff s} \lambda P(s) \biggr|_{s = 0} = 0
	.\]
\end{proofbox}

\begin{lemma}
	Let $X$ be $\Mkv(Q)$ and $Y$ its jump chain. Then $\pi$ is invariant for $X$ if and only if $\mu$ defined by $\mu_x = q_x \pi_x$ is invariant for $Y$.
\end{lemma}

\begin{proofbox}
	We want to show $\pi Q = 0$ if and only if $\mu P = \mu$. Since $q_x(p_{xy} - \delta_x) = q_{xy}$, we have
	\begin{align*}
		(\pi Q)_y &= \sum_{x \in I} \pi_x q_{xy} = \sum_{x \in I} \pi_x q_x (p_{xy} - \delta_{xy}) \\
			  &= \mu_x(p_{xy} - \delta_{xy}) = \sum_x \mu_x p_{xy} - \mu_y \\
			  &= (\mu P)_y - \mu_y.
	\end{align*}
\end{proofbox}

\begin{theorem}
	Let $X$ be irreducible and recurrent with generator $Q$. Then $X$ has an invariant measure, which is unique up to scalar multiplication.
\end{theorem}

\begin{proofbox}
	Assume $|I| > 1$. Then by irreducibility, $q_x > 0$ for all $x$. For $Y$, $\nu^{x}(y)$ is an invariant measure which is unique up to scalar multiplication. Hence, $\frac{\nu^{x}(y)}{q_y}$ is an invariant measure for $X$, which is also unique.
\end{proofbox}

\begin{definition}
	Let $T_x = \inf\{t \geq J_1 \mid X_t = x\}$ be the \emph{first return time}\index{first return time} to $x$.
\end{definition}

\begin{lemma}
	Assume $q_y > 0$. Define
	\[
		\mu^{x}(y) = \mathbb{E}_x \Biggl[ \int_{0}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr]
	.\]
	Then we have
	\[
	\mu^{x}(y) = \frac{\nu^{x}(y)}{q_y}
	.\]
\end{lemma}

\begin{proofbox}
	\begin{align*}
		\mu^{x}(y) &= \mathbb{E}_x\Biggl[ \int_{0}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr] \\
			   &= \mathbb{E}_x \Biggl[ \sum_{n = 0}^{H_x - 1} \mathbbm{1}(Y_n = y) S_{n+1} \Biggr] \\
			   &= \mathbb{E}_x \Biggr[ \sum_{n = 0}^{\infty} S_{n+1} \mathbbm{1}(Y_n = y, n \leq H_x - 1) \Biggl] \\
			   &= \sum_{n = 0}^{\infty} \mathbb{E}_x[S_{n+1} \mid Y_n = y, n \leq H_{x} - 1] \mathbb{P}_x(Y_n = y, n \leq H_x - 1).
	\end{align*}
	By the Markov property, this equals
	\begin{align*}
		& \sum_{n = 0}^{\infty} \mathbb{E}_x [S_{n+1} \mid Y_n = y] \mathbb{P}_x(Y_n = y, n \leq H_x - 1) \\
		=& \sum_{n = 0}^{\infty} \frac{1}{q_y} \mathbb{P}_x(Y_n = y, n \leq H_x - 1) \\
		=& \frac{1}{q_y} \sum_{n = 0}^{\infty} \mathbb{E}_x[\mathbbm{1}(Y_n = y, n \leq H_x - 1)] \\
		=& \frac{1}{q_y} \mathbb{E}_x \Biggl[ \sum_{n = 0}^{\infty} \mathbbm{1}(Y_n = y, n \leq H_x - 1) \Biggr] \\
		=& \frac{1}{q_y} \mathbb{E}_x \Biggl[ \sum_{n = 0}^{H_x - 1} \mathbbm{1}(Y_n = y) \Biggr] = \frac{\nu^{x}(y)}{q_y}.
	\end{align*}	
\end{proofbox}

\begin{definition}
	A recurrent state $x$ is called \emph{positive recurrent}\index{positive recurrent} if
	\[
	m_x = \mathbb{E}_x[T_x] < \infty
	.\]
	Else, the state is \emph{null recurrent}\index{null recurrent}.
\end{definition}

\begin{theorem}
	Let $X \sim \Mkv(Q)$ be irreducible. Then the following are equivalent:
	\begin{enumerate}[\normalfont(a)]
		\item Every state is positive recurrent.
		\item Some state is positive recurrent.
		\item $X$ is non-explosive and has an invariant distribution $\lambda$.
	\end{enumerate}
	Moreover, when \emph{(c)} holds,
	\[
	\lambda(x) = \frac{1}{q_x m_x}
	.\]
\end{theorem}

\begin{proofbox}
	Clearly (a) implies (b). We show (b) implies (c). Assume that $q_x > 0$ for all $x$. Let $x$ be a positive recurrent state. Then all states are recurrent, so $Y$ is recurrent and hence $X$ is non-explosive.

	As $Y$ is recurrent, $\nu^{x}$ is an invariant measure for $Y$. So $\mu^{x}(y) = \frac{\nu^{x}(y)}{q_y}$ is invariant for $X$. Also,
	\[
		\mu^{x}(y) = \mathbb{E}_x \Biggl[ \int_{0}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr]
	.\]
	Hence,
	\[
		\sum_{y \in I} \mu^{x}(y) = \mathbb{E}_x \Biggl[ \int_{0}^{T_x} \sum_{y \in I} \mathbbm{1}(X_t = y) \diff t \Biggr] = \mathbb{E}_x[T_x] < \infty
	.\]
	Hence we have an invariant distribution of the form
	\[
	\frac{\mu^{x}(y)}{\mathbb{E}_x[T_x]}
	.\]
	Finally, we show (c) implies (a). From our lemma, the measure
	\[
	\beta(y) = \lambda(y) q_y
	\]
	is an invariant measure for $Y$. Since $\sum \lambda(y) = 1$, $\lambda(x) > 0$ for some $x$. Since $Y$ is irreducible, for any $y \in I$, $x$ leads to $y$, in say $n$ steps. Since $\beta P^{n} = \beta$, we have $\lambda(y) > 0$.

	Fix some $x \in I$. Then $\lambda(x) > 0$. Define
	\[
	a^{x}(y) = \frac{\beta(y)}{\lambda(x) q_x}
	,\]
	for all $y \in I$. This is invariant for $Y$, and $a^{x}(y) = 1$. By the theorem for discrete time chains, $a^{x}(y) \geq \nu^{x}(y)$ for all $y \in I$. Also if we define
	\[
		\mu^{x}(y) = \mathbb{E}_x \Biggl[ \int_{0}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr]
	,\]
	then we know
	\[
	\mu^{x}(y) = \frac{\nu^{x}(y)}{q_y}
	,\]
	and $\sum \mu^{x}(y) = \mathbb{E}_x[T_x] = m_x$. Then,
	\begin{align*}
		m_x &= \sum_y \mu^{x}(y) = \sum_y \frac{\nu^{x}(y)}{q_y} \\
		    &\leq \sum_y \frac{a^{x}(y)}{q_y} = \sum_y \frac{\beta(y)}{\lambda(x) q_x q_y} \\
		    &= \sum_y \frac{\lambda(y) q_y}{\lambda(x) q_x q_y} = \frac{1}{\lambda(x) q_x} \sum_y \lambda(y) \\
		    &= \frac{1}{\lambda(x) q_x} < \infty.
	\end{align*}
	Hence $x$ is positive recurrent, so all states are positive recurrent.

	Also if (c) holds, then $X$ is recurrent, so $Y$ is recurrent, so $a^{x}(y) = \nu^{x}(y)$. Hence
	\[
	m_x = \frac{1}{\lambda(x) q_x}
	.\]
\end{proofbox}

\begin{exbox}
	On $\mathbb{Z}^{+}$, consider the birth and death process with $q_{i,i+1} = \lambda q_i$, $q_{i,i-1} = \mu q_i$ and $q_{ii} = - (\lambda + \mu) q_i$.

	Then $(\lambda/\mu)^{L}$ is invariant for $Y$, so
	\[
	\pi_i = \frac{1}{q_i} \biggl( \frac{\lambda}{\mu} \biggr)^{i}
	\]
	is invariant for $X$. Take $q_i = 2^{i}$ and $\lambda = \frac{3\mu}{2}$. Then,
	\[
	\pi_i = \biggl( \frac{3}{4} \biggr)^{i}
	\]
	is invariant for $X$. This is summable, so $X$ has an invariant distribution. However, $X$ is not positive recurrent as $Y$ is transient. Therefore $X$ is transient.

	In order to not contradict our previous theorem, this means $X$ is explosive.
\end{exbox}

\begin{lemma}
	Fix $t > 0$ and set $Z_n = X_{nt}$, where $(Z_n)$ is a discrete-time Markov chain.

	Then $x$ is recurrent for $X$ if and only if $x$ is recurrent for $Z$.
\end{lemma}

This is an exercise in the example sheets.

\begin{theorem}
	Let $X \sim \Mkv(Q)$ be recurrent, irreducible, and $\lambda$ be a measure. Then
	\[
	\lambda Q = 0 \iff \lambda P(s) = \lambda
	\]
	for all $s > 0$.
\end{theorem}

\begin{proofbox}
	Any measure $\lambda$ such that $\lambda Q = 0$ is unique (up to scalar multiplication).

	Similarly any measure $\lambda$ such that $\lambda P(s) = \lambda$ is unique (up to scalar multiplication). Then $(X_n)_{n = 0}^{\infty}$ is a discrete time chain with transition matrix $P(1)$, and moreover it is irreducible as $X$ is irreducible, and recurrent from our previous lemma, hence the invariant measure $\lambda$ is unique.

	Then it is enough to show that $\mu^{x} Q = 0$ and $\mu^{x} P(s) = \mu^{x}$ for all $s$, where
	\[
		\mu^{x}(y) = \mathbb{E}_x \Biggl[ \int_{0}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr]
	.\]
	Moreover $\mu^{x}(y) = \frac{\nu^{x}(y)}{q_y}$, and since $Y$ is recurrent $\nu^{x}(y)$ is an invariant measure for $Y$. So $\mu^{x}(y)$ is an invariant measure for $X$, meaning $\mu^{x}Q = 0$.

	Also, by the Strong Markov property,
	\[
		\mathbb{E}_x \Biggl[ \int_{0}^{s} \mathbbm{1}(X_t = y) \diff t \Biggr] = \mathbb{E}_x \Biggl[ \int_{T_x}^{T_x + s} \mathbbm{1}(X_t = y) \diff t \Biggr]
	.\]
	Thus,
	\begin{align*}
		\mu^{x}(y) &= \mathbb{E}_x \Biggl[ \int_{0}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr] \\
			   &= \mathbb{E}_x \Biggl[ \int_{0}^{s} \mathbbm{1}(X_t = y) \diff t \Biggr] + \mathbb{E}_x \Biggl[ \int_{s}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr] \\
			   &= \mathbb{E}_x \Biggl[ \int_{T_x}^{T_x + s} \mathbbm{1}(X_t = y) \diff t \Biggr] + \mathbb{E}_x \Biggl[ \int_{s}^{T_x} \mathbbm{1}(X_t = y) \diff t \Biggr] \\
			   &= \mathbb{E}_x \Biggl[ \int_{s}^{T_x + s} \mathbbm{1}(X_t = y) \diff t \Biggr] \\
			   &= \mathbb{E}_x \Biggl[ \int_{0}^{\infty} \mathbbm{1}(X_{u+s} = y, u < T_x) \diff u \Biggr] \\
			   &= \int_{0}^{\infty} \mathbb{P}_x(X_{u+s} = y, u < T_x) \diff u \\
			   &= \int_{0}^{\infty} \sum_{z \in I} \mathbb{P}_x (X_u = z, X_{u+s} = y, u < T_x) \diff u \\
			   &= \sum_{z \in I} P_{zy}(s) \mathbb{E}_x \Biggl[ \int_{0}^{T_x} \mathbbm{1}(X_u = z) \diff u \Biggr] \\
			   &= \sum_{z \in I} \mu^{x}(z) P_{zy}(s).
	\end{align*}
	Hence $\mu^{x} = \mu^{x} P(s)$ as required.
\end{proofbox}

\subsection{Convergence to Equilibrium}
\label{sub:convergence_to_equilibrium}

\begin{theorem}
	Let $X \sim \Mkv(Q)$ be irreducible and non-explosive, and let $\lambda$ be an invariant distribution. Then for all $x, y \in S$,
	\[
	P_{xy}(t) \to \lambda (y)
	,\]
	as $t \to \infty$.
\end{theorem}

\begin{lemma}
	For the semigroup $P(t)$ and for all $t \geq 0$, $h \geq 0$,
	\[
		|P_{xy}(t+h) - P_{xy}(t)| \leq 1 - e^{-q_x h} \leq q_x h
	.\]
\end{lemma}

\begin{proofbox}
	The latter inequality is easy to show, from $e^{x} \geq 1+x$. For the former, note
	\begin{align*}
		|P_{xy}(t+h) - P_{xy}(t)| &= \biggl| \sum_{z \in I} P_{xz}(h) P_{zy}(t) - P_{xy}(t) \biggr| \\
					  &= \biggl| \sum_{z \neq x} P_{xz}(h) P_{zy}(t) - P_{xy}(t)(1 - p_{x x}(h)) \biggr| \\
					  &\leq 1 - p_{x x}(h) = \mathbb{P}_x(X(h) \neq x) \\
					  &\leq \mathbb{P}_x(J_1 \leq h) = 1 - e^{-q_x h}.
	\end{align*}
\end{proofbox}

Now we return to proving our theorem.

\begin{proofbox}
	Fix $\eps > 0$ and $h > 0$ such that $q_x h < \eps/2$. Consider the Markov chain $(Z_n) = (X_{nh})_{n = 0}^{\infty}$. Then $Z_n$ is irreducible and aperiodic. As $X$ is positive recurrent, $\lambda P(h) = \lambda$, meaning $\lambda$ is an invariant distribution for $(Z_n)$.

	By discrete-time Markov chain results, for all $x, y$,
	\[
		P_{xy}(nh) \overset{n \to \infty}{\to} \lambda(y)'
	.\]
	Hence there exists some $n_0$ such that for all $n \geq n_0$, $|p_{xy}(nh) - \lambda(y)| \leq \eps/2$. Let $t \geq n_0h$. Then there exists $n \geq n_0$ such that $nh \leq t < (n+1)h$, so from our previous lemma,
	\begin{align*}
		|p_{xy}(t) - \lambda(y)| &\leq |p_{xy}(t) - p_{xy}(nh)| - |p_{xy}(nh) - \lambda(y)| \\
					 &\leq q_x(t - nh) + \frac{\eps}{2} \leq q_x h + \frac{\eps}{2} \\
					 &\leq \eps.
	\end{align*}
\end{proofbox}

\subsection{Ergodic Theory}
\label{sub:ergodic_theory}

\begin{theorem}
	Let $X \sim \Mkv(\lambda, Q)$ be irreducible. Then as $t \to \infty$,
	\[
		\frac{1}{t} \int_{0}^{t} \mathbbm{1}(X_s = x) \diff s \to \frac{1}{q_x m_x}
	,\]
	with probability 1.

	If $X$ is positive recurrent and $\pi$ is the unique invariant distribution, if $f : I \to \mathbb{R}$ is bounded, then
	\[
	\frac{1}{t} \int_{0}^{t}f(X_s) \diff s \to \sum_{x \in I}f(x) \pi(x)
	.\]
\end{theorem}

The proof of this is skipped.

\subsection{Reversibility}
\label{sub:reversibility}

\begin{theorem}
	Let $X \sim \Mkv(Q)$ be irreducible, non-explosive with invariant distribution $\pi$. Let $X_0 \sim \pi$. Fix $T > 0$ and set
	\[
	\hat X_t = X_{T - t}
	,\]
	for $0 \leq t \leq T$. Then $\hat X \sim \Mkv(\hat Q)$ and invariant distribution $\pi$, where
	\[
	\hat q_{xy} = \pi(y) \frac{q_{yx}}{\pi(x)}
	.\]
	Moreover, $\hat Q$ is irreducible and non-explosive.
\end{theorem}

\begin{proofbox}
	Note that $\hat Q$ is a $Q$-matrix, as we can check $\hat q_{xy} \geq 0$ for all $x \neq y$, and
	\[
	\sum_{y} \hat q_{xy} = \frac{1}{\pi(x)} \sum_{y} \pi(y) q_{yx} = \frac{1}{\pi(x)} (\pi Q)_{x} = 0
	.\]
	Also $\hat Q$ is irreducible, and
	\[
		(\pi \hat Q)_{x} = \sum_{x} \pi(x) \hat q_{xy} = \sum_{x} \pi(y) q_{yx} = \pi(y) \sum_{x} q_{yx} = 0
	.\]
	So $\pi$ is invariant for $\hat Q$. Now let $0 = t_0 \leq t_1 \leq \cdots \leq t_n = T$, $x_1, \ldots, x_n \in I$ and set $s_i = t_i - t_{i-1}$. Then, if we define
	\[
	\hat P_{xy}(t) = \frac{\pi(y)}{\pi(x)} P_{yx}(t)
	,\]
	then we get
	\begin{align*}
		\mathbb{P}(\hat X_{t_0} &= x_0, \hat X_{t_1} = x_1, \ldots, \hat X_{t_n} = x_n) \\
					&= \mathbb{P}(X_0 = x_n, \ldots, X_{T-t_1} = x_1, X_{T} = x_0) \\
					&= \pi(x_n) P_{x_n x_{n-1}}(s_n) \cdots P_{x_1x_0}(s_1) \\
					&= \pi(x_n) \hat P_{x_{n-1}x_n} \frac{\pi(x_{n-1})}{\pi(x_n)} \cdots \hat P_{x_0 x_1}(s_1) \frac{\pi(x_0)}{\pi(x_1)} \\
					&= \pi(x_0) \hat P_{x_0x_1}(s_1) \cdots \hat P_{x_{n-1}x_n}(s_n).
	\end{align*}
	Hence $\hat X$ is Markov with transition semigroup $(\hat P(t))$, so now we show that $\hat Q$ generates $(\hat P(t))$. Hence we show $\hat P(t)$ is the minimal non-negative solution to the Kolmogorov backwards equation with $\hat Q$, or
	\[
		(\hat P(t))' = \hat Q \hat P(t)
	.\]
	Indeed, we have
	\begin{align*}
		\hat P'_{xy}(t) &= \frac{\pi(y)}{\pi(x)} P'_{yx}(t) = \frac{\pi(y)}{\pi(x)} \sum_{z} P_{yz}(t) q_{zx} \\
				&= \frac{1}{\pi(x)} \sum_{z} \pi(z) \hat P_{zy}(t) q_{zx} \\
				&= \sum_{z} \hat q_{xz} \hat p_{zy}(t) = (\hat Q \hat P(t))_{xy}.
	\end{align*}
	To show minimality, suppose $R$ is another solution to $R'(t) = \hat Q R(t)$. Then defining
	\[
	\bar R_{xy}(t) = \frac{\pi(y)}{\pi(x)} R_{yx}(t)
	,\]
	as before we would get $\bar R'(t) = \bar R(t) Q$. Then as $P'(t) = P(t) Q$ and is minimal, $\bar R \geq P$. Hence $R \geq \hat P$.

	Also, as $X$ is irreducible and non-explosive with invariant distribution $\pi$, $X$ is (positive) recurrent. Hence $\pi P(t) = \pi$ for all $t$. Thus,
	\[
	\sum_{y} \hat P_{xy}(t) = \frac{1}{\pi(x)} \sum_{y} \pi(y) P_{yx}(t) = \frac{1}{\pi(x)}(\pi P(t))_{x} = \frac{1}{\pi(x)}\pi(x) = 1
	.\]
	Hence,
	\[
		1 = \sum_{y} \hat P_{xy}(t) = \sum_{y} \mathbb{P}_x(Z_t = y) = \sum_{y} \mathbb{P}_x(Z_t = y, t < \zeta) = \mathbb{P}_x(t < \zeta)
	.\]
	Now since $\mathbb{P}_x(\zeta > t) = 1$ for all $t$, we get $\mathbb{P}_x(\zeta = \infty) = 1$, meaning the process is non-explosive.
\end{proofbox}

\begin{definition}
	Let $X \sim \Mkv(Q)$. It is called \emph{reversible}\index{reversible} if for all $T > 0$, $(X_t)_{0 \leq t \leq T}$ and $(X_{T - t})_{0 \leq t \leq T}$ have the same distribution.
\end{definition}

\begin{definition}
	A measure $\lambda$ and a $Q$-matrix $Q$ are said to be in \emph{detailed balance}\index{detailed balance} if for all $x, y$,
	\[
	\lambda(x) q_{xy} = \lambda(y) q_{yx}
	.\]
\end{definition}

\begin{lemma}
	If $Q$ and $\lambda$ are in detailed balance, then $\lambda$ is invariant for $Q$.
\end{lemma}

\begin{proofbox}
	\[
		(\lambda Q)_{y} = \sum_{x} \lambda (x) q_{xy} = \sum_{x} \lambda(y) q_{yx} = \lambda(y) \sum_{x} q_{yx} = 0
	.\]
\end{proofbox}

\begin{remark}
	To find an invariant measure, first check the detailed balance equations.
\end{remark}

\begin{lemma}
	Let $X \sim \Mkv(Q)$ be irreducible and non-explosive, $\pi$ a distribution, and $X_0 \sim \pi$. Then $\pi$ and $Q$ are in detailed balance if and only if $(X_t)_{t \geq 0}$ is reversible.
\end{lemma}

\begin{proofbox}
	$X$ is reversible if and only if $Q = \hat Q$ and $\pi$ is an invariant distribution. But this holds if and only if
	\[
	\pi(x)q_{xy} = \pi(y)q_{yx}
	,\]
	i.e. $\pi$ and $Q$ are in detailed balance.
\end{proofbox}

\begin{definition}
	A \emph{birth and death chain}\index{birth and death chain} $X$ is a continuous time Markov chain on $\mathbb{N} = \{0, 1, 2, \ldots\}$ with, for $x \geq 1$,
	\[
	q_{x,x-1} = \mu_x, \qquad q_{x,x+1} = \lambda_x, \qquad q_{x,x} = - \mu_x - \lambda_x
	,\]
	and for $x = 0$, $q_{0, 1} = \lambda_0$ and $q_{0,0}=-\lambda_0$.
\end{definition}

\begin{lemma}
	A measure $\pi$ is invariant for a birth and death chain if and only if it solves the detailed balance equation.
\end{lemma}

\begin{proofbox}
	We have seen that if it solves the detailed balance equation, then it is invariant.

	For the converse, let $\pi$ be an invariant measure. Then $\pi Q = 0$, so for all $j \geq 1$,
	\begin{align*}
		&(\pi Q)_j = 0 \\
		\iff&\pi_{j-1}q_{j-1,j} + \pi_jq_{j,j} + \pi_{j+1}q_{j+1,j} = 0 \\
		\implies & \pi_{j-1} \lambda_{j-1} + \pi_{j+1}\mu_{j+1} - \pi_j(\lambda_j + \mu_j) = 0 \\
		\implies &\pi_{j+1}\mu_{j+1} - \pi_j\lambda_j = \pi_j\mu_j - \pi_{j-1}\lambda_{j-1}.
	\end{align*}
	For $j = 0$, we get $\pi_1\mu_1 - \pi_0\mu_0 = 0$. Using induction, we get $\pi_{j+1}\mu_{j_1} = \pi_j\lambda_j$.
\end{proofbox}

\newpage

\section{Queueing Theory}
\label{sec:queueing_theory}

\emph{Queueing theory}\index{queueing theory} is the study of a continuous Markov process, where
\begin{itemize}
	\item Customers arrive, to get served.
	\item Serving happens at some rate.
	\item After getting served, the customers leave.
\end{itemize}

Applications of queueing theory include telecommunication, traffic control, industrial engineering and project management.

Shout out Kendall, Kingman, Frank Kelly (big ups Cambridge), Burke, Jackson, Khinchin? and some others.

Examples of queueing theory questions are:
\begin{itemize}[Q.]
	\item What is the equilibrium queue length?
	\item What is the busy period?
	\item What is the time spent by a customer in the queue? What is the waiting time (including the service time)?
\end{itemize}

We use $M/G/k$ notation. Here,
\begin{itemize}
	\item $M$ is the Markovian arrival: meaning that the customers arrive according to a Poisson process of rate $\lambda$.
	\item $G$ is the general distribution, which is the service time distribution (which is iid). If we swap the $G$ for a $M$, that indicates that we have iid $\Exp(\mu)$ service times.
	\item $k$ is the number of servers (we will consider $k = 1$ or $k = \infty$).
\end{itemize}

Let $X_t$ be the queue length (including customers being served) at time $t$. Then $I = \{0, 1, 2, \ldots\}$.

For $M/M/1$ and $M/M/\infty$, $X$ is a Markov chain. Moreover, since the number of customers increases or decreases by one, $X$ is a birth and death chain.

For $M/M/1$, we have $q_{i,i+1} = \lambda$, $q_{i,i-1} = \mu$.

For $M/M/\infty$, we have $q_{i,i+1} = \lambda$, $q_{i,i-1} = i \mu$.

\begin{theorem}
	Consider a $M/M/1$ process with rates $\lambda, \mu$. Let $\rho = \lambda/\mu$. Then the queue length $X$ is:
	\begin{itemize}
		\item Transient $\iff \rho > 1$.
		\item Recurrent $\iff \rho \leq 1$.
		\item Positive recurrent $\iff \rho < 1$.
	\end{itemize}
	In the positive recurrent case, the invariant distribution is
	\[
	\pi(n) = (1 - \rho)\rho^{n}
	.\]
	If $\rho < 1$ and $X_0 \sim \pi$, then the wait time for a customer that arrives at time $t$ is $\Exp(\mu - \lambda)$.
\end{theorem}

\begin{proofbox}
	The jump chain $Y$ is a biased SRW on $\mathbb{N}$ (with reflection at the origin). Thus $Y$ (and hence $X$) is transient if $\lambda > \mu$, and recurrent if $\lambda \leq \mu$.

	There is no explosion, as $q_i = (\lambda + \mu)$ is bounded, hence positive recurrence is equivalent to having an invariant distribution. As $X$ is a birth and death chain, an invariant measure solves the detailed balance equation.

	Therefore $\pi(n) \lambda = \pi(n+1)\mu$, or
	\[
	\pi(n+1) = \pi(n) \frac{\lambda}{\mu} = \cdots = \pi(0)\biggl( \frac{\lambda}{\mu} \biggr)^{n+1}
	.\]
	Hence $\pi$ is normalizable if and only if $\frac{\lambda}{\mu} = \rho < 1$. We can normalise it to $\pi(n) = (1-\rho)\rho^{n}$.

	Hence $\rho$ is the distribution of a (shifted) geometric random variable with parameter $1 - \rho$, i.e. $\pi \sim Z-1$, where $Z \sim \Geom(1 - \rho)$.

	If $\rho < 1$ and $X_0 \sim \pi$, then $X_t \sim \pi$, as $X$ is recurrent. The wait time $W$ of a customer arriving at time $t$ is
	\[
	W = \sum_{i = 1}^{X_t+1} T_i
	,\]
	where $T_i \sim \Exp(\mu)$, independent of $X_t$. As $X_t+1 \sim \Geom(1-\rho)$ independent of $(T_i)$, we get
	\[
	W \sim \Exp(\mu(1 - \rho)) = \Exp(\mu - \lambda)
	.\]
	The expected queue length at equilibrium is
	\begin{align*}
		\mathbb{E}_\pi[X_t] &= \mathbb{E}_\pi[Z- 1] = \mathbb{E}_\pi[Z] - 1 = \frac{1}{1 - \rho} - 1 \\
				    &= \frac{\rho}{1 - \rho} = \frac{\lambda}{\mu - \lambda}.
	\end{align*}
\end{proofbox}

Now we look at $M/M/\infty$ processes.

\begin{theorem}
	The queue length $X$ is positive recurrent, with invariant distribution $\Poisson(\rho)$, with $\rho = \frac{\lambda}{\mu}$.
\end{theorem}

\begin{proofbox}
	As $X$ is a birth-and-death process, we just solve the detailed balance equation:
	\[
	\lambda \pi_{n-1} = n \mu \pi_n \implies \pi_n = \frac{1}{n} \cdot \frac{\lambda}{\mu} \pi_{n-1} = \cdots = \frac{1}{n!} \biggl( \frac{\lambda}{\mu} \biggr)^{n} \pi_0.
	\]
	This is always normalizable with
	\[
	\pi_n = e^{-\lambda/\mu} \biggl( \frac{\lambda}{\mu} \biggr)^{n} \frac{1}{n!},
	\]
	hence $\pi \sim \Poisson(\rho)$. We also need to show $X$ is non-explosive to conclude $X$ is positive recurrent.

	One such way is to show the jump chain $Y$ is recurrent. In fact, we will show it is positive recurrent, hence that is has an invariant measure. Define $\mu_i = \pi_i q_i$. Then $\mu$ is an invariant measure for $Y$, so it is enough to check that $\mu$ is normalizable:
	\[
	\mu_i = (i \mu + \lambda) e^{-\rho} \frac{\rho^{i}}{i!} = \rho \mu \biggl( e^{-\rho} \frac{\rho^{i-1}}{i!} (i + \rho) \biggr),
	\]
	which is summable as
	\[
	\sum \frac{\rho^{i-1}}{i!} (i + \rho) = \sum \frac{\rho^{i-1}}{(i-1)!} + \sum \frac{\rho^{i}}{i!} < \infty.
	\]
\end{proofbox}

\subsection{Burke's theorem}
\label{sub:burkes_theorem}

Let $A$ and $D$ denote the arrival and departure processes associated with a queue. Then,
\begin{itemize}
	\item $A$ increases by $1$ when $X$ increases by $1$.
	\item $D$ increases by $1$ when $X$ decreases by $1$.
\end{itemize}
So $X_t = X_0 + A_t - D_t$. Then we are given that $A$ is a Poisson process of rate $\lambda$.

\begin{remark}
	A Poisson process does not have an invariant distribution, but still has the following time-reversal property: if $N$ is a Poisson process of rate $\lambda$, then for any $T > 0$, $\hat N_t = N_T - N_{T - t}$ is again a Poisson process of rate $\lambda$ on $[0,T]$.
\end{remark}

\begin{proofbox}
	Conditioned on $N_T = n$, the distribution of jump times is
	\[
		\frac{n!}{T^{n}} \mathbbm{1}(0 \leq t_1 \leq \cdots \leq t_n \leq T),
	\]
	which gives the result, and also we can use the fact the independent increments are Poisson.
\end{proofbox}

\begin{theorem}[Burke]
	Consider an $M/M/1$ queue with $\mu > \lambda > 0$, or an $M/M/\infty$ queue with $\mu, \lambda > 0$. At equilibrium (i.e. $X_0 \sim \pi$), $D$ is a Poisson process of rate $\lambda$ and $X_t$ is independent of $(D_s \mid s \leq t)$.
\end{theorem}

\begin{remark}
	\begin{enumerate}
		\item[]
		\item $X_0 \sim \pi$ is essential. If $X_0 = 5$ in an $M/M/1$ queue, then the first departure happens at $\Exp(\mu)$ time, and not $\Exp(\lambda)$.
		\item The process $(X_s \mid s \leq t)$ and $(D_s \mid s \leq t)$ are not independent. This is because $D$ jumps exactly when $X$ decreases by one.
	\end{enumerate}
\end{remark}

\begin{proofbox}
	As $X$ is a birth-and-death process, $\pi$ satisfies the detailed balance equation. That is, if $X_0 \sim \pi$, then $X$ is reversible. Then for a fixed $T > 0$ with $\hat X_t = X_{T-t}$, we have
	\[
		(\hat X_t \mid 0 \leq t \leq T) \overset{d}{=} (X_t \mid 0 \leq t \leq T).
	\]
	The arrival process $\hat A$ for $\hat X$ (till time $T$) is Poisson process $\lambda$. But $\hat A_t = D_T - D_{T - t}$ is a Poisson process of rate $\lambda$, and since the time reversal of a Poisson process on $[0,T]$ is again a Poisson process on $[0,T]$, this implies $(D_t \mid 0 \leq t \leq T)$ is a Poisson process of rate $\lambda$ on $[0,T]$.

	Since $T > 0$ is arbitrary, this determines the finite dimensional distribution of $D$, and hence determines the distribution of $D$, meaning $D \sim PP(\lambda)$.

	As $X_0$ is independent of $(A_s \mid 0 \leq s \leq T)$, $\hat X_0$ is independent of $(\hat A_s \mid 0 \leq s \leq T)$, meaning $X_T$ is independent of $(D_s \mid 0 \leq s \leq T)$.
\end{proofbox}

\subsection{Queues in Tandem}
\label{sub:queues_in_tandem}

Suppose that there is an $M/M/1$ queue with parameters $\lambda$ and $\mu_1$. After a customer is served, they immediately join a second single-server queue with service rate $\mu_2$.

Let $X$ and $Y$ denote the queue lengths of the two queues respectively. For $(X, Y)$, $I = \{0, 1, 2, \ldots\}^2$, and the rates are
\[
	(m, n) \to
	\begin{cases}
		(m+1,n) & \text{rate } \lambda, \\
		(m-1,n+1) & \text{rate } \mu_1, \\
		(m,n-1) & \text{rate } \mu_2.
	\end{cases}
\]
\begin{theorem}
	$(X, Y)$ is positive recurrent if and only if $\lambda < \mu_1$ and $\lambda < \mu_2$, and then the invariant distribution is given by
	\[
	\pi(m, n) = (1 - \rho_1)\rho_1^{m}(1- \rho_2)\rho_2^{n}
	\]
	with $\rho_1 = \frac{\lambda}{\mu_1}$, $\rho_2 = \frac{\lambda}{\mu_2}$. Hence, at equilibrium, $X_t$ and $Y_t$ are independent.
\end{theorem}

%lecture 15

\begin{proofbox}
	We can directly check that $\pi Q = 0$. As the rates are bounded, $(X, Y)$ is non-explosive.

	However, we can find a more elegant proof. Note that the marginal $X$ is an M/M/1 queue. Thus $X$ is positive recurrent if and only if $\lambda < \mu_1$ with invariant distribution
	\[
	\pi^{1}(m) = (1 - \rho_1)\rho_1^{m}.
	\]
	By Burke's theorem, if $X_0 \sim \pi^{1}$, then the departure process of the first queue is $PP(\lambda)$, which is the arrival process for the second queue. So the second queue is again M/M/1, with rates $(\lambda, \mu_2)$, with invariant distribution
	\[
	\pi^{2}(n) = (1 - \rho_2)\rho_2^{n},
	\]
	if $\lambda < \mu_2$.

	So if $X_0 \sim \pi^{1}$ and $Y_0 \sim \pi^{2}$ are independent, then $X_t \sim \pi^{1}$ (as $X$ is recurrent), and also by Burke's theorem, $X_t$ is independent of $(D_s \mid s \leq t)$, and also independent of $Y_0$.

	Hence $X_t$ is independent of $Y_t$. Also $Y_t \sim \pi^{2}$ (as $Y$ is recurrent), so $(X_t, Y_t) \sim (\pi^{1}, \pi^{2}) = \pi$. Then $\pi$ is invariant for $(X, Y)$, from the next proposition.
\end{proofbox}

\begin{proposition}
	Let $Z$ be irreducible, $\pi$ a distribution, and $\pi P(t) = \pi$ for all $t$. Then $\pi$ is invariant for $Z$.
\end{proposition}

\subsection{Jackson's Network}
\label{sub:jacksons_network}\index{Jackson's Network}

Consider a network of $N$ single-server queues, with arrival rates $\lambda_k$ and service rates $\mu_k$, for $k = 1, 2, \ldots, N$.

After service, each customer in queue $i$ moves to queue $j$ with probability $p_{ij}$, or exits the system with probability $p_{i0} = 1 - \sum p_{ij}$. We assume that $p_{ii} = 0$, i.e. they don't return to the same queue, and $p_{i0} > 0$, and also that the system is irreducible, i.e. a customer in queue $i$ has a positive probability of visiting queue $j$ at some later time.

Thus $I = \{0, 1, 2, \ldots\}^{N}$, where if $x = (x_1, x_2, \ldots, x_N)$, then $x_i$ is the number of customers in queue $i$.

If $n \in I$, i.e. $n = (n_1, n_2, \ldots, n_N)$ and $e_i = (0, \ldots, 0, 1, 0, \ldots, 0)$, then
\[
\begin{cases}
	q_{n,n+e_i} = \lambda_i, \\
	q_{n,n-e_i+e_j} = \mu_i p_{ij}, \\
	q_{n,n-e_i} = \mu_i p_{i0}.
\end{cases}
\]
\begin{definition}
	We say a vector $\bar \lambda = (\bar \lambda_1, \ldots, \bar \lambda_N)$ satisfies the \emph{traffic equation}\index{traffic equation} if for all $1 \leq i \leq N$,
	\[
		\bar \lambda_i = \lambda_i + \sum_{j = 1}^{N} \bar \lambda_j p_{ji} - \bar \lambda_i p_{ii}.
	\]
\end{definition}

\begin{remark}
	$\bar \lambda_i$ is the effective arrival rate at queue $i$.
\end{remark}

\begin{lemma}
	There exists a unique solution to the traffic equation.
\end{lemma}

\begin{proofbox}
	The uniqueness is an exercise in example sheet 3.

	For existence, let $p_{00} = 1$. Then $P + (p_{ij})^{N}$ is a stochastic matrix. The corresponding (discrete time) Markov chain $(Z_n)$ is absorbing at $0$. Thus the communicating class $\{1, 2, \ldots, N\}$ is \emph{transient}.

	Thus is $V_i$ is the number of visits to state $i$ by $Z$, then starting fro $Z_0$, $\mathbb{E}[V_i] < \infty$ for all $i = 1 2, \ldots, N$.

	Let $\mathbb{P}(Z_0 = i) = \frac{\lambda_i}{\lambda}$ for $i = 1, 2, \ldots, N$, where $\lambda$ is the sum of $\lambda_i$. Then, for all $1, 2, \ldots, N$,
	\begin{align*}
		\mathbb{E}[V_i] &= \mathbb{E}\Biggl[ \sum_{i = 1}^{\infty}\mathbbm{1}(Z_n = i) \Biggr] \\
				&= \mathbb{P}(Z_0 = i) + \sum_{n = 0}^{\infty}\mathbb{P}(Z_{n+1} = i) \\
				&= \frac{\lambda_i}{\lambda} + \sum_{j = 1}^{N}p_{ji} \sum_{n = 0}^{\infty} \mathbb{P}(Z_n = j) \\
				&= \frac{\lambda_i}{\lambda} + \sum_{j = 1}^{N} p_{ji} \mathbb{E}[V_j].
	\end{align*}
	Multiplying through by $\lambda$ and setting $\bar \lambda_i = \lambda \mathbb{E}[V_i]$, we get that
	\[
	\bar \lambda_i = \lambda_i + \sum_{j = 1}^{N} \bar \lambda_j p_{ji}.
	\]
\end{proofbox}

\begin{theorem}
	Assume that the traffic equations have the solution $\bar \lambda_i$ such that $\bar \lambda_i < \mu_i$ for all $i = 1, \ldots, N$. Then the Jackson Network is positive recurrent with invariant distribution
	\[
	\pi(n) = \sum_{i = 1}^{N} (1 - \bar \rho_i) \bar \rho_i^{n_i},
	\]
	where $\bar \rho_i = \frac{\bar \lambda_i}{\mu_i}$.

	At equilibrium, the departure processes from each queue form independent Poisson processes with rates $\bar \lambda_i p_{i0}$.
\end{theorem}

\begin{remark}
	\begin{enumerate}
		\item[]
		\item At equilibrium, the queue lengths $X_t^{i}$ are independent for a fixed time $t$.
		\item The equilibrium for Jackson's network is non-reversible, but there is partial reversibility.
	\end{enumerate}
\end{remark}

\begin{lemma}[Partial detailed balance]\index{partial detailed balance}
	Let $X$ be a Markov process on $I$ and $\pi$ be a measure. Assume that for each $ \in I$, there is a partition of $I \setminus \{x\}$ as
	\[
		I \setminus \{x\} = I_1^{x} \cup I_2^{x} \cup \cdots,
	\]
	such that for all $i \geq i$,
	\[
	\sum_{y \in I_i^{x}} \pi(x) q_{xy} = \sum_{y \in I_i^{x}} \pi(y) q_{yx}.
	\]
\end{lemma}


\newpage

\printindex

\end{document}
